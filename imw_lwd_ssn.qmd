---
title: "Stream network variation in large wood dynamics"
author: "dan.auerbach@dfw.wa.gov"
date: "`r Sys.Date()`"
format:
  html:
    embed-resources: true
    theme: yeti 
    code-fold: true
    toc: true
    toc-location: left
    grid:
      sidebar-width: 180px
      body-width: 1100px
      margin-width: 20px
---



emailed:
  1. [How] Does network/riverscape position affect temporal variation in wood density? (this follows from past reflections from Kirk and Will) and
  2. [How] Are changes in wood density followed by changes in other measures of habitat form? (this follows from past comments from Joe) and
  3. Do changes in coho juvenile abundance or productivity correspond with changes in habitat form heterogeneity/diversity
 
I suggest the first is testable by regressing interannual variation relative to topographic/spatial attributes and the second by time series cross-correlations (i.e., does wood ‘lead’ pools). I am very comfortable rejecting them, but my initial hypotheses are that
  - yes, steeper and wider reaches will show greater year to year change as wood is transported and/or deposited and
  - yes, increases in density will be followed by increases in the prevalence of pool forms and increased bankfull width
  - yes, increases in productivity will be associated with greater complexity/heterogeneity [I’m aware this is weakly specified, but I mean increased ‘types’ at size and/or stream scales]
 
The figures below illustrate progress towards #1. The first multipanel scatter shows temporal variation in large wood density as the per-site CV over years relative to drainage area, slope, and bankfull width in the columns left to right. The DA and slope are derived from NHDplusHighRes, the bankfull width is minimum across years of the per-year median across transects. The rows distinguish streams by complex, with Little Anderson and Seabeck further split out due to their differences in overall size, higher sampling density, and channel units (many more ‘dry’ reaches). The CV y-axis is fixed across all panels, the x-axes are fixed per column, helping to show stream/basin-scale differences in the site samples (e.g., Little Anderson and Seabeck have much narrower widths; Germany has a much higher proportion of steeper sloped reaches; etc. and also evident in the second map figure). Subsets of sites in particular streams show evidence of univariate relationships, and I think we can recognize/describe several meaningful patterns that accord with fluvial geomorphic principles (e.g., variation in several streams is higher in some steep and headwater reaches then decreases moving downstream before increasing again in wider reaches near outlets), but I would say that these data do not support a generally consistent or generically portable relationship of wood variation to site width, slope, or drainage area. Examining the maps for how slopes are distributed and where the highest CVs occurred was especially helpful for me, for example, clarifying how Germany has considerably steeper headwaters than Mill (with Abernathy splitting the difference) and a fairly topologically distinct sampling footprint (i.e., more upper basin, fewer mainstem, relative to the other LC). Having reached this version, it should also be relatively straightforward to further stratify by mainstem-trib or subset to ‘primary rearing’ sites, as we’ve discussed in the past. Pending feedback, my next steps on this will be to fit some models to substantiate the ‘not much relationship’ claim on #1 and to better examine #2. Pending that, I’ll turn back to #3.

weekend ultra plain language thoughts for intro:
  - wood in streams is important
  - wood in streams is dynamic, it's understood to change in time (on a 'medium phase/frequency' relative to faster changing flow and slower changing geomorphic character, even to bedrock/base level)
  - but despite this importance and recognition of change in time, and despite the very significant ongoing investments to 're-wood' PNW riverscapes, few studies have had the spatiotemporal scope of data collection to track large wood dynamics over more than a decade at numerous sites throughout the drainage network of 7 replicate streams.

flows?
  - link Brinkerhoff results? (easy now with COMIDs in place)
  - no NWM3.0 to +HR, anything else? daily high res precip from Maurer/CIG...

Test habitat portfolio theory: how does var_stream relate to var_sites? per stream, what proportion of sites have
  - strong positive autocorrelation, indicating slower/smoother fluctuations in values ['low frequency' conditions]?
  - strong negative autocorrelation, indicating more rapidly reversing values ['high frequency' conditions]

do more with among-site phase/synchrony via cross-corr? all pairwise cross-corr ...refactor around corrr


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 9, fig.height = 10)

library("tidyverse", quietly = T)
library("sf")
library("patchwork")
library("gt")
theme_set(theme_minimal()) 

library(SSN2)

dir_data_common <- "~/T/DFW-Team WDFW Watershed Synthesis - data_common"
epsg <- 2927 #WA state standard; NAD83(HARN)/ft

load("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/imw_hab_250205.RData")
rm(hab, transects_excluded)
# sf_hr_flw <- readRDS("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/sf_hr_flw_imw.rds") |> 
#   select(cmplx_desc, Name, HUC12, NHDPlusID, length_km, dasqkm_tot, elev_min, slope)
ssns <- readRDS("ssns_list.rds")

sf_ssn_sites <- map(
  ssns, ~.x$obs |> 
    select(-locID, -netID, -netgeom)
  ) |> 
  bind_rows()
#if ever rebuilding can reduce some of this name wrangling
sf_ssn_edges <- map(
  ssns, ~.x$edges |> 
    select(-netID, -netgeom) |> 
    mutate(
      strm = str_split_i(basename(.x$path),"_",2),
      cmplx_strm = case_when(
          str_detect(strm,"Deep") ~ grep("Deep", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"WTwin") ~ grep("West", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"ETwin") ~ grep("East", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"Stav") ~ grep("Stav", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"Seab") ~ grep("Seab", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"Beef") ~ grep("Beef", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"Ander") ~ grep("Ander", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"Mill") ~ grep("Mill", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"Aber") ~ grep("Aber", names(pal_cmplx_strm), value = T), 
          str_detect(strm,"Germ") ~ grep("Germ", names(pal_cmplx_strm), value = T)
        ),
      strm = str_sub(cmplx_strm,4,30),
      Name = NULL
    )
  ) |> 
  bind_rows() |> 
  select(cmplx_desc, cmplx_strm, strm, HUC12, NHDPlusID, rid, everything())

# as_tibble(sf_ssn_edges) |> #glimpse()
#   count(cmplx_strm, strm) |> arrange(n)

```

```{r rebuild_nhdplus_highres, eval=FALSE}
#well then!!! nhdplusTools::get_3dhp 
#https://doi-usgs.github.io/nhdplusTools/articles/get_3dhp_data.html
#also: https://doi-usgs.github.io/nhdplusTools/articles/nhdplushr.html
#but using known H12s from already DL'd HUC4 GDBs

library(mapview)

hr_gdb <- c("NHDPLUS_H_1708_HU4_GDB.gdb", "NHDPLUS_H_1711_HU4_GDB.gdb")

hr_h12 <- map(hr_gdb,
              ~st_read(file.path(dir_data_common, "nhdphr/17/",.x), layer = "WBDHU12") |> 
                select(HUC12, Name, HUType, AreaSqKm, ToHUC)
) |> 
  bind_rows() |> #for manual name filtering: as_tibble() |> select(-Shape) |> arrange(Name) |> view()
  filter(
    HUC12 %in% c(
      "171100210304", #Deep
      "171100210303", #W Twin
      "171100210302", #E Twin
      "171100180107", #BBC incl other HC
      "170800030605", #Mill
      "170800030604", #Abernathy
      "170800030603" #Germany
    )
  ) |> #mapview()
  st_transform(st_crs(epsg)) |> 
  select(-AreaSqKm, - ToHUC) |> 
  mutate(
    cmplx_desc = case_when(
      str_detect(Name, "Deep|Twin") ~ "Straits of Juan de Fuca",
      str_detect(Name, "Beef") ~ "Hood Canal",
      str_detect(Name, "Mill|Aber|Ger") ~ "Lower Columbia"
    )
  )


# #no HUC12 identifier on flowlines so need to subset spatially
# st_read(
#   "~/T/DFW-Team WDFW Watershed Synthesis - data_common/nhdphr/17/NHDPLUS_H_1708_HU4_GDB.gdb", 
#   query="select * from \"NHDFlowline\" limit 1") |> 
#   colnames()

#memory hungry, builds single object of ALL 500K lines in 1708 and 1711
hr_flw <- map(hr_gdb,
    ~st_read(file.path(dir_data_common, "nhdphr/17/",.x), layer = "NHDFlowline") |> 
      select(NHDPlusID, GNIS_Name, length_km = LengthKM) |> 
      st_zm() |> 
      st_transform(st_crs(epsg)) |> 
      st_cast("LINESTRING") 
  ) |> 
  bind_rows()

#spatially subset lines by HUC12 polys adding HUC12 ids, 
#expands for 5 small lines that cross between Mill & Abernathy so deduplicate
#then add select VAA physiographic & EROM flow fields
hr_flw_imw <- st_join(
  hr_flw[hr_h12,],
  hr_h12
  ) |> 
  distinct(NHDPlusID, .keep_all = T) |> 
  left_join(
    map(hr_gdb,
        ~st_read(file.path(dir_data_common, "nhdphr/17/",.x), layer = "NHDPlusFlowlineVAA") |> #names()
          select(
            NHDPlusID, #FromNode, ToNode,
            order = StreamOrde,
            dasqkm_cat = AreaSqKm, #locl catchment
            dasqkm_tot = TotDASqKm, #cumulative 
            slope = Slope, #unitless
            slopelgth = SlopeLenKm, #the length used to calc slope
            elev_min = MinElevSmo, elev_max = MaxElevSmo #in cm
          )
    ) |> bind_rows(),
    by = "NHDPlusID"
  ) |> 
  left_join(
    map(hr_gdb,
        ~st_read(file.path(dir_data_common, "nhdphr/17/",.x), layer = "NHDPlusEROMMA") |> #names()
          select(NHDPlusID, QEMA, VEMA)
    ) |> bind_rows(),
    by = "NHDPlusID"
  ) |> 
  mutate(
    across(starts_with("elev"), ~./100)
    NHDPlusID = as.character(NHDPlusID)
  )

as_tibble(hr_flw_imw) |> count(cmplx_desc, Name)

# #no huc14 in HR gdb or via nhdplusTools::get_huc
# #could probably get something via https://hydro.nationalmap.gov/arcgis/rest/services/wbd/MapServer/7
# #but going to deal with HC manually during SSNbler anyway
# #so leaving streams unseparated for now
# hr_flw_imw |> filter(cmplx_desc == "Hood Canal") |> mapview(zcol = "GNIS_Name")

saveRDS(hr_flw_imw, file = "~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/sf_hr_flw_imw.rds")

```

## SSNbler

Sites with at least 10 years of observations were associated to the NHDplus High Resolution flowlines using the `SSNbler` package (Peterson et al. 2024). 

Topological issues in the hydrography (split paths, 3-way convergences, etc.) were manually examined and corrected, and appropriate matching of site points to stream lines was visually confirmed.

```{r func_to_sfn, eval=FALSE}
#first examined trying to do all 4 HC streams at once, but 
#whereas prior LC tests have been 'mostly clean, nearly rooted tree', dropping/fixing relatively few instances,
#the HC geometry is a relative mess with lots to drop and frontal line segs
#trying a GIS coarse clip via st_union(st_convex_hull(sites)) was really unsatisfying
#so using a graph backtrace from known/desired outlets found manually: mapview(sf_hr_flw)

to_sfn <- function(h12, nhd_outlet) {
  sfn <- sf_hr_flw |> 
    filter(
      dasqkm_tot > 0,
      HUC12 == h12, 
    ) |> 
    sfnetworks::as_sfnetwork() 
  sfn <- sfn |> 
    tidygraph::convert(
      tidygraph::to_local_neighborhood,
      node = filter(as_tibble(sfn, "edges"), NHDPlusID == nhd_outlet)$to,
      mode = "in", 
      order = tidygraph::with_graph(sfn, tidygraph::graph_order())
      ,
      .clean = T
    )
  return(sfn)
}
```

### edges and obs

```{r ssnbler_hc_sta, eval=FALSE}
strm_to_ssn <- "171100180107_Stavis_55000800121057" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "171100180107", nhd_outlet = "55000800121057")
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sf_site_meta |> filter(str_detect(strm, "Stavis"))), zcol = c("slope","strm"))

#first pass reveals issues
edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to),
  lsn_path = dir_ssn,
  check_topology = TRUE,
  snap_tolerance = 1,
  topo_tolerance = 20,
  overwrite = TRUE
)
#zero issues, 1 outlet
edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
#errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) # |> as_tibble()

#but lots of gratuitous pseudonodes
mapview::mapview(list(
  flw = edges, nod = nodes,
  #, err = errors
  sites = sf_site_meta |> filter(str_detect(strm, "Stavis"))
  ), zcol = c("dasqkm_tot","nodecat",
              #,"error"
              "strm"
              ))
# #in this case, most straightforward fix is just drop/truncate sections above any sites
# edges |> 
#   #semi_join(as_tibble(nodes) |> filter(nodecat=="Pseudonode", pointid != 24), by = c("tonode" = "pointid")) |> mapview()
#   anti_join(as_tibble(nodes) |> filter(nodecat=="Pseudonode", pointid != 24), by = c("tonode" = "pointid")) |> mapview()

#now overwrite after drops
#SSNbler::lines_to_lsn is called again after pipe, 'streams' is first arg
edges <- edges |> 
  anti_join(
    as_tibble(nodes) |> 
      filter(nodecat=="Pseudonode", pointid != 24),
    by = c("tonode" = "pointid")) |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #drop any tiny headwaters with 0 dasqkm_tot
      edges |> filter(dasqkm_tot == 0) |> pull(NHDPlusID)
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE,
  snap_tolerance = 1,
  topo_tolerance = 20,
  overwrite = TRUE
)

#snap tol of 100ft is good starting value based on prior work
# #but have to increase to get 014, 026, 053
# sf_site_meta |> filter(str_detect(strm, "Stavis")) |> anti_join(as_tibble(obs), by = "site") |> select(site)
# plot(1:nrow(obs), sort(obs$snapdist))

sites <- sf_site_meta |> filter(str_detect(strm, "Stavis")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
sites$geometry[sites$site == "STA033"] <- st_point(c(1053709 - 200, 835133 + 100))

obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 145,
  save_local = TRUE, overwrite = TRUE
)
#check snaps are good
#initially STA033 went to 38 but looks like it should have been 39
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

#now do it again to add edge covars now that points are associated to lines
obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 145,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)

```

```{r ssnbler_hc_sea, eval=FALSE}
strm_to_ssn <- "171100180107_Seabeck_55000800007261" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "171100180107", nhd_outlet = "55000800007261")
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sf_site_meta |> filter(str_detect(strm, "Seabeck"))), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn,
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)
# 1 outlet 1 issue
edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) # |> as_tibble()

sites <- sf_site_meta |> filter(str_detect(strm, "Seabeck")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 

mapview::mapview(
  list(flw = edges, nod = nodes, err = errors, sites = sites),
  zcol = c("dasqkm_tot","nodecat","error", "strm"))

#now overwrite after drops
edges <- edges |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #drop the edge with smallest drainage area at complex converg
      #confirmed manually is best choice trib running alongside "Northwest Dancing Deer Way"
      edges |> 
        inner_join(
          as_tibble(errors) |> filter(error == "Complex Confluence"),
          by = c("tonode" = "pointid")    
        ) |> 
        arrange(tonode, dasqkm_tot) |> 
        slice_min(dasqkm_tot, by = tonode) |> 
        pull(NHDPlusID)
      ,
      #drop any tiny headwaters with 0 dasqkm_tot
      edges |> filter(dasqkm_tot == 0) |> pull(NHDPlusID)
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE,
  snap_tolerance = 1,
  topo_tolerance = 20,
  overwrite = TRUE
)

# have to increase snapdist >100 for 032 and 118
# sort(set_names(obs$snapdist, obs$site))
# sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
# dropping SEA064 since on the dropped trib at complex confluence
# and nudging SEA121
sites <- sites |> filter(site != "SEA064")
sites$geometry[sites$site == "SEA121"] <- st_point(c(1058715 - 200, 835456.7))

obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 125,
  save_local = TRUE, overwrite = TRUE
)
#check snaps are good
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

#now do it again to add edge covars now that points are associated to lines
obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 125,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)

```

```{r ssnbler_hc_bbc, eval=FALSE}
strm_to_ssn <- "171100180107_BigBeef_55000800196966" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "171100180107", nhd_outlet = "55000800196966")
sites <- sf_site_meta |> filter(str_detect(strm, "Beef")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sites), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn, 
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)
# 1 outlet 1 issue
edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) 
#20 pseudonodes but relatively few at periphery so removing most would create separate subgraphs
#could drop pointid %in% c(10, 60) and perhaps a few others but leaving for now
mapview::mapview(
  list(flw = edges, nod = nodes, err = errors, sites = sites),
  zcol = c("dasqkm_tot","nodecat","error", "strm"))

edges <- edges |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #drop the edge with smallest drainage area at complex converg, confirmed manually
      edges |> 
        inner_join(
          as_tibble(errors) |> filter(error == "Complex Confluence"),
          by = c("tonode" = "pointid")    
        ) |> 
        arrange(tonode, dasqkm_tot) |> 
        slice_min(dasqkm_tot, by = tonode) |> 
        pull(NHDPlusID)
      ,
      #drop tiny headwaters with 0 dasqkm_tot
      edges |> filter(dasqkm_tot == 0) |> pull(NHDPlusID)
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 215,
  save_local = TRUE, overwrite = TRUE
)
sort(set_names(obs$snapdist, obs$site))
sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
#check snaps are good
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

#add edge covars now that points are associated to lines
obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 215,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)

```

```{r ssnbler_hc_and, eval=FALSE}
strm_to_ssn <- "171100180107_LAnderson_55000800045870" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "171100180107", nhd_outlet = "55000800045870")
sites <- sf_site_meta |> filter(str_detect(strm, "Anderson")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sites), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn, 
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)
#no further cleaning...1 outlet, no errors, only a couple of nonsig pseudonodes
edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
#errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) 
mapview::mapview(
  list(sites = sites, flw = edges, nod = nodes),
  zcol = c("strm","dasqkm_tot","nodecat"))

#snaps all look good but AND002 appears to be on a tiny trib with no flowline
#so dropping as snapping to rid 16 like AND031 would be wrong
obs <- SSNbler::sites_to_lsn(
  sites = sites |> filter(site != "AND002"),
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 180,
  save_local = TRUE, overwrite = TRUE
)
sort(set_names(obs$snapdist, obs$site))
sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

#add edge covars now that points are associated to lines
obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 215,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)

```

```{r ssnbler_st_deep, eval=FALSE}
strm_to_ssn <- "171100210304_Deep_55000800078356" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "171100210304", nhd_outlet = "55000800078356")
sites <- sf_site_meta |> filter(str_detect(strm, "Deep")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sites), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn, 
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) 
mapview::mapview(
  list(sites = sites, flw = edges, nod = nodes, err = errors),
  zcol = c("strm","dasqkm_tot","nodecat","error"))

edges <- edges |> 
    anti_join(
    as_tibble(nodes) |> 
      filter(
        nodecat=="Pseudonode",
        !(pointid %in% c(28,30,31,32,158,217,242,300,348,429,439))
        ),
    by = c("tonode" = "pointid")) |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #drop the edge with smallest drainage area at complex converg, confirmed manually
      edges |> 
        inner_join(
          as_tibble(errors) |> filter(error == "Complex Confluence"),
          by = c("tonode" = "pointid")    
        ) |> 
        arrange(tonode, dasqkm_tot) |> 
        slice_min(dasqkm_tot, by = tonode) |> 
        pull(NHDPlusID)
      ,
      #plus the extra tiny subbasin above one of the dropped complex conf
      "55000800267304","55000800267305","55000800116385","55000800116384",
      #could drop a trib that causes a bad snap of DEW765: "55000800267373",
      #drop tiny headwaters 
      edges |> filter(dasqkm_tot < 0.01) |> 
        #left_join(as_tibble(nodes), by = c("fromnode"="pointid")) #to confirm nothing further upstream
        pull(NHDPlusID)
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

# nudging DEW765, better than dropping 55000800267373
sites$geometry[sites$site == "DEW765"] <- st_point(c(776165 + 200, 1045445))

obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 125,
  save_local = TRUE, overwrite = TRUE
)
sort(set_names(obs$snapdist, obs$site))
sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
#check snaps are good
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 125,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)

```

```{r ssnbler_st_wtwn, eval=FALSE}
strm_to_ssn <- "171100210303_WTwin_55000800192401" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "171100210303", nhd_outlet = "55000800192401")
sites <- sf_site_meta |> filter(str_detect(strm, "West")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sites), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn, 
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) 
mapview::mapview(
  list(sites = sites, flw = edges, nod = nodes, err = errors),
  zcol = c("strm","dasqkm_tot","nodecat","error"))

edges <- edges |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #dropping multiple tiny edges at complex converg, confirmed manually
      edges |> 
        inner_join(
          as_tibble(errors) |> filter(error == "Complex Confluence"),
          by = c("tonode" = "pointid")    
        ) |> 
        arrange(tonode, dasqkm_tot) |> 
        filter(tonode %in% c(78, 160)) |> 
        pull(NHDPlusID)
      ,
      #plus the extra tiny subbasin above the third downstream complex conf
      "55000800002776","55000800078491","55000800002777",
      #drop tiny headwaters 
      edges |> filter(dasqkm_tot < 0.01) |> 
        #left_join(as_tibble(nodes), by = c("fromnode"="pointid")) #to confirm nothing further upstream
        pull(NHDPlusID)
      ,
      #plus a tiny trib that makes a bad snap for DEW068
      "55000800040717"
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

#only need dist to 145 except for DEW661
obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 235,
  save_local = TRUE, overwrite = TRUE
)
sort(set_names(obs$snapdist, obs$site))
sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
#check snaps are good
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 235,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)
```

```{r ssnbler_st_etwn, eval=FALSE}
strm_to_ssn <- "171100210302_ETwin_55000800078543" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "171100210302", nhd_outlet = "55000800078543")
sites <- sf_site_meta |> filter(str_detect(strm, "East")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sites), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn, 
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) 
mapview::mapview(
  list(sites = sites, flw = edges, nod = nodes, err = errors),
  zcol = c("strm","dasqkm_tot","nodecat","error"))

edges <- edges |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #confirmed manually
      edges |> 
        inner_join(
          as_tibble(errors) |> filter(error == "Complex Confluence"),
          by = c("tonode" = "pointid")    
        ) |> 
        arrange(tonode, dasqkm_tot) |> 
        slice_min(dasqkm_tot, by = tonode) |> 
        pull(NHDPlusID)
      ,
      #drop tiny headwaters 
      edges |> filter(dasqkm_tot < 0.01) |> 
        #left_join(as_tibble(nodes), by = c("fromnode"="pointid")) #to confirm nothing further upstream
        pull(NHDPlusID)
      ,
      #drop to stop bad snaps for DEW446, DEW158, DEW048
      "55000800154522","55000800002784","55000800040752"
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

#nudging to keep a smaller snapdist
sites$geometry[sites$site == "DEW106"] <- st_point(c(810339 - 100 , 1038275))

obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 110,
  save_local = TRUE, overwrite = TRUE
)
sort(set_names(obs$snapdist, obs$site))
sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
#check snaps are good
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 110,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)

```

```{r ssnbler_lc_mill, eval=FALSE}
strm_to_ssn <- "170800030605_Mill_55000300323139"  #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "170800030605", nhd_outlet = "55000300323139")
sites <- sf_site_meta |> filter(str_detect(strm, "Mill")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sites), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn, 
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) 
mapview::mapview(
  list(sites = sites, flw = edges, nod = nodes, err = errors),
  zcol = c("strm","dasqkm_tot","nodecat","error"))

edges <- edges |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #confirmed manually
      edges |> 
        inner_join(
          as_tibble(errors) |> filter(error == "Complex Confluence"),
          by = c("tonode" = "pointid")    
        ) |> 
        arrange(tonode, dasqkm_tot) |> 
        slice_min(dasqkm_tot, by = tonode) |> 
        pull(NHDPlusID)
      ,
      #keep the shorter path in a divergence, obvi could do otherwise
      edges |> 
        semi_join(
          as_tibble(errors) |> filter(error == "Downstream Divergence"),
          by = c("fromnode" = "pointid")    
        ) |> 
        slice_max(length_km) |> pull(NHDPlusID)
      ,
      #drop tiny headwaters 
      edges |> filter(dasqkm_tot < 0.01) |> 
        #left_join(as_tibble(nodes), by = c("fromnode"="pointid")) |> print(n=Inf) #to confirm nothing further upstream
        pull(NHDPlusID)
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

#all good, nice
obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 110,
  save_local = TRUE, overwrite = TRUE
)
sort(set_names(obs$snapdist, obs$site))
sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
#check snaps are good
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 110,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)

```

```{r ssnbler_lc_aber, eval=FALSE}
strm_to_ssn <- "170800030604_Abernathy_55000300323141" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "170800030604", nhd_outlet = "55000300323141")
sites <- sf_site_meta |> filter(str_detect(strm, "Aber")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sites), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn, 
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) 
mapview::mapview(
  list(sites = sites, flw = edges, nod = nodes, err = errors),
  zcol = c("strm","dasqkm_tot","nodecat","error"))

edges <- edges |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #confirmed manually
      edges |> 
        inner_join(
          as_tibble(errors) |> filter(error == "Complex Confluence"),
          by = c("tonode" = "pointid")    
        ) |> 
        arrange(tonode, dasqkm_tot) |> 
        slice_min(dasqkm_tot, by = tonode) |> 
        pull(NHDPlusID)
      ,
      #side trib 55000300297598 makes this work, which also has dasqkm > 0.01
      edges |> 
        semi_join(
          as_tibble(errors) |> filter(error == "Downstream Divergence"),
          by = c("fromnode" = "pointid")    
        ) |> 
        slice_max(length_km) |> pull(NHDPlusID)
      ,
      #drop tiny headwaters 
      edges |> filter(dasqkm_tot < 0.01) |> 
        #left_join(as_tibble(nodes), by = c("fromnode"="pointid")) |> print(n=Inf) #to confirm nothing further upstream
        pull(NHDPlusID)
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

#nudges
sites$geometry[sites$site == "ABR020"] <- st_point(c(965646 + 100, 325921))
sites$geometry[sites$site == "ABR016"] <- st_point(c(961030 - 100, 356205 - 300))

obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 110,
  save_local = TRUE, overwrite = TRUE
)
sort(set_names(obs$snapdist, obs$site))
sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
#check snaps are good
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 110,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)
```

```{r ssnbler_lc_germ, eval=FALSE}
strm_to_ssn <- "170800030603_Germany_55000300400697" #HUC12, stream, outlet NHDPlusID
dir_ssn <- file.path("../ssn_data", strm_to_ssn)

sfn <- to_sfn(h12 = "170800030603", nhd_outlet = "55000300400697")
sites <- sf_site_meta |> filter(str_detect(strm, "Germ")) |> 
  select(cmplx_strm:bankfull_width_max, contains("per100")) 
mapview(list(sfn = as_tibble(sfn, "edges"), sites = sites), zcol = c("slope","strm"))

edges <- SSNbler::lines_to_lsn(
  streams = as_tibble(sfn, "edges") |> select(-from, -to), lsn_path = dir_ssn, 
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

edges <- edges |> 
  left_join(read_csv(file.path(dir_ssn, "noderelationships.csv")), by = "rid") |> 
  select(NHDPlusID, rid, fromnode, tonode, everything()) 
nodes <- sf::st_read(file.path(dir_ssn, "nodes.gpkg"))
errors <- sf::st_read(file.path(dir_ssn, "node_errors.gpkg")) 
mapview::mapview(
  list(sites = sites, flw = edges, nod = nodes, err = errors),
  zcol = c("strm","dasqkm_tot","nodecat","error"))

edges <- edges |> 
  select(-fromnode, -tonode) |> 
  filter(
    !(NHDPlusID %in% c(
      #crossing headwaters, satellite shows clearcut, trimming the whole mess 
      "55000300400709","55000300246167",
      "55000300246168","55000300374602","55000300272014","55000300323343",
      #fixes divergence & complex convergence
      "55000300272053", 
      "55000300323375", 
      #drop tiny headwaters; lots (~89) here
      edges |> filter(dasqkm_tot < 0.01) |> 
        #left_join(as_tibble(nodes), by = c("fromnode"="pointid")) |> print(n=Inf) #to confirm nothing further upstream
        pull(NHDPlusID)
    ))
  ) |> 
  SSNbler::lines_to_lsn(
  lsn_path = dir_ssn,
  check_topology = TRUE, snap_tolerance = 1, topo_tolerance = 20, overwrite = TRUE
)

#nudges
sites$geometry[sites$site == "GER007"] <- st_point(c(977178 + 100, 365569.7))
sites$geometry[sites$site == "GER008"] <- st_point(c(977290, 374293 - 100))
sites$geometry[sites$site == "GER087"] <- st_point(c(970016.4 + 100, 371990.9))
# #looks like an error in 2024 longitude, bringing this way west of where it should be
# sf_site_year |> filter(site == "GER050") |> mapview()
#using the exact 2023 longlat
sites$geometry[sites$site == "GER050"] <- st_point(c(979893.1, 358158))

obs <- SSNbler::sites_to_lsn(
  sites = sites,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 110,
  save_local = TRUE, overwrite = TRUE
)
sort(set_names(obs$snapdist, obs$site))
sites |> anti_join(as_tibble(obs), by = "site") |> select(site)
#check snaps are good
mapview::mapview(list(
  edges = edges, 
  obs = obs |> select(site, rid),
  sites = sites
  ), zcol = c("rid","rid","strm"))

obs <- SSNbler::sites_to_lsn(
  sites = obs |> 
    left_join(
      as_tibble(edges) |> 
        select(rid, NHDPlusID, length_km:slope),
      by = "rid")
  ,
  edges = edges, lsn_path = dir_ssn, file_name = "obs",
  snap_tolerance = 110,
  save_local = TRUE, overwrite = TRUE
)

rm(sites, sfn, edges, nodes, errors, obs, strm_to_ssn, dir_ssn)

```

### pred pts

```{r walk_pred_pts, eval=FALSE}
#for prediction points,
#use startpoints of unsampled reaches
#LC streams have many more reaches and many are longer
# #initial testing with only LC added length filter
# #looks arbitrary but workable for other complexes/streams? maybe not Seabeck & LA
# as_tibble(sf_hr_flw) |> count(Name) |> arrange(desc(n)) |> 
#   left_join(
#     as_tibble(sf_hr_flw) |> filter(length_km > 0.1) |> count(Name), by = "Name"
#   )

#this is relatively slow at the `sites_to_lsn` step for LC
walk(
  list.files("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/ssn_data/", pattern = "^17", full.names = T)
  ,
  \(dir_ssn){
    edges <- sf::st_read(file.path(dir_ssn, "edges.gpkg"))
    obs <- sf::st_read(file.path(dir_ssn, "obs.gpkg"))
    
    pred_lines <- edges |>
      anti_join(as_tibble(obs), by = "rid")
      #ggplot() + stat_ecdf(aes(length_km)) + labs(subtitle = dir_ssn) 

    pred_pts <- as_tibble(pred_lines) |> 
      select(-geom) |>
      mutate(geometry = lwgeom::st_startpoint(pred_lines)) |>
      st_as_sf()
    #print(ggplot(pred_pts) + geom_sf() + labs(subtitle = basename(dir_ssn)))
    
    preds <- SSNbler::sites_to_lsn(
      sites = pred_pts,
      edges = edges,
      save_local = TRUE,
      lsn_path = dir_ssn,
      file_name = "preds.gpkg",
      snap_tolerance = 100,
      overwrite = TRUE
    )
  }
)

```

### updist

```{r walk_updist, eval=FALSE}
#somewhat inefficient read/write but keeping separated for modularity
walk(
  list.files("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/ssn_data/", pattern = "^17", full.names = T)
  ,
  \(dir_ssn){
    edges <- sf::st_read(file.path(dir_ssn, "edges.gpkg"))
    obs <- sf::st_read(file.path(dir_ssn, "obs.gpkg"))
    preds <- sf::st_read(file.path(dir_ssn, "preds.gpkg"))

    #add edge length and updist
    edges <- SSNbler::updist_edges(
      edges = edges,
      save_local = TRUE,
      lsn_path = dir_ssn,
      calc_length = TRUE 
    )
    #add same for sites
    site.list <- SSNbler::updist_sites(
      sites = list(
        obs = obs,
        preds = preds
      ),
      edges = edges,
      length_col = "Length",
      save_local = TRUE,
      lsn_path = dir_ssn
    )
  }
)
```

### AFVs

```{r walk_afv, eval=FALSE}
#still somewhat inefficient read/write but keeping separated for modularity
#add propinfluence (relative weight at confluence) and additivefunctionval (product of propinf along path)
#could use slope or other weighting than dasqkm_tot
#then add those to the obs and preds
#which take the value of their associated edges (possibly duplicated for sites that share an edge)

walk(
  list.files("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/ssn_data/", pattern = "^17", full.names = T)
  ,
  \(dir_ssn){
    edges <- SSNbler::afv_edges(
      edges = sf::st_read(file.path(dir_ssn, "edges.gpkg")),
      infl_col = "dasqkm_tot",
      segpi_col = "areaPI",
      afv_col = "afvArea",
      lsn_path = dir_ssn
    )
    site.list <- SSNbler::afv_sites(
      sites = list(
        obs = sf::st_read(file.path(dir_ssn, "obs.gpkg")),
        preds = sf::st_read(file.path(dir_ssn, "preds.gpkg"))
      ),
      edges = edges,
      afv_col = "afvArea",
      save_local = TRUE,
      lsn_path = dir_ssn
    )
  }
)
```

### assembled

```{r list_assembled_with_dist, eval=FALSE}
#careful with overwrite!!!
ssns <- map(
  set_names(
    list.files("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/ssn_data", pattern = "^17", full.names = T),
    list.files("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/ssn_data", pattern = "^17")
  )
  ,
  \(dir_ssn){
    edges <- sf::st_read(file.path(dir_ssn, "edges.gpkg"))
    obs <- sf::st_read(file.path(dir_ssn, "obs.gpkg"))
    preds <- list(preds = sf::st_read(file.path(dir_ssn, "preds.gpkg")))
    
    ssn <- SSNbler::ssn_assemble(
      edges = edges, lsn_path = dir_ssn,
      obs_sites = obs, preds_list = preds,
      #ssn_path = file.path(dir_ssn, paste0(str_split_i(basename(dir_ssn),"_",2),".ssn")),
      ssn_path = file.path(dir_ssn, paste0(basename(dir_ssn),".ssn")),
      import = TRUE, check = TRUE, afv_col = "afvArea",
      overwrite = TRUE
    )
    
    SSN2::ssn_create_distmat(
      ssn,
      predpts = "preds",
      among_predpts = TRUE,
      overwrite = TRUE
      )

    return(ssn)
  }
)

saveRDS(ssns, "ssns_list.rds")
```


## EDA and corrr

Prior to model fitting, we examined the underlying physiographic differences among basins as captured in the NHDplus measures and evaluated the correlations among these measures for the reach segments associated with IMW sites.

```{r ssn_edges}
ssn_edges <- as_tibble(sf_ssn_edges) |> 
  select(-HUC12, -rid, -geom) |> 
  left_join(
    as_tibble(sf_ssn_sites) |> #267
      distinct(NHDPlusID, .keep_all = T) |> #226, several reaches have more than 1 site
      select(NHDPlusID, site, ends_with("mean"), starts_with("vlwd"))
    ,
    by = "NHDPlusID"
  ) |> 
  mutate(
    imw_sampled = if_else(!is.na(site), "with site", "without site")
    )
```

```{r ssn_sites}
ssn_sites <- as_tibble(sf_ssn_sites) |> #267
  #      distinct(NHDPlusID, .keep_all = T) |> #226, several reaches have more than 1 site
  select(
    cmplx_abrv, cmplx_desc, cmplx_strm, strm, NHDPlusID, site,
    dasqkm_tot,
    elev_min,
    slope,
    bankfull_width_mean,
    vlwd_per100_mean, vlwd_per100_sd
    #ends_with("mean") #,starts_with("vlwd")
  ) |> 
  mutate(
    vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean
  )
```

### stream network-wide elevation vs drainage area 

```{r gg_ssn_edges_elev_vs_DA}
map(
  c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
  ,
  ~ggplot() +
    geom_point(
      data = ssn_edges |> 
        filter(cmplx_desc == .x, imw_sampled == "without site") |> 
        mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5)))
      ,
      aes(dasqkm_tot, elev_min, color = slope_f), alpha = 0.8, shape = 20, size = 0.5,
      show.legend = F
    ) +  
    geom_point(
      data = ssn_edges |> 
        filter(cmplx_desc == .x, imw_sampled == "with site") |> 
        mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5)))
      ,
      aes(dasqkm_tot, elev_min, fill = slope_f), alpha = 1, shape = 24, size = 2, color = "black",
      show.legend = T
    ) +
    geom_hline(yintercept = 1, color = "#ADD8E6", linetype = 2) + #linewidth = 0.5
    geom_hline(yintercept = 200, color = "#A45DEC", linetype = 2) + #linewidth = 0.5
    geom_hline(yintercept = 400, color = "#BF4CA0", linetype = 2) + #linewidth = 0.5
    geom_hline(yintercept = 600, color = "#FFA500", linetype = 2) + #linewidth = 0.5
    scale_x_log10(
      limits = c(0.01, 100),
      breaks = scales::breaks_log(), 
      labels = scales::label_log()
    ) +
    scale_color_manual(values = c("lightblue","darkblue","tan","orange"),
                       aesthetics = c("color","fill")
    ) +
    guides(color = guide_colorsteps(title = "Avg. reach slope"),
           fill = guide_none()) +
    theme(legend.position = "bottom") +
    facet_wrap(~strm, nrow = 1) +
    labs(
      subtitle = .x,
      x = "Reach DA (km^2)", y = "Reach min. elev. (m)"
    )
) |> 
  wrap_plots(nrow = 3, guides = "collect") & 
  theme(legend.position = "bottom")

ggsave("f_ssn_edges_elev_DA.png", width = 9, height = 11, dpi = 120, bg = "white")  
```

### mapped additive function values 

```{r gg_ssn_edges_map_afv}
# #upDist values comparable within complex for ST and LC
# #BBC different scale than other HC
# map(
#   c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
#   ,
#   ~ggplot(mapping = aes(color = upDist)) +
#     geom_sf(data = filter(sf_ssn_edges, cmplx_desc == .x)) +
#     geom_sf(data = filter(sf_ssn_sites, cmplx_desc == .x)) +
#     wacolors::scale_color_wa_c("puget")
#   ) |> 
#   wrap_plots(nrow = 3)

#AFV normalized by stream but has somewhat different geography for BBC and Germany
map(
  c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
  ,
  ~ggplot(mapping = aes(color = afvArea)) +
    geom_sf(data = filter(sf_ssn_edges, cmplx_desc == .x)) +
    geom_sf(data = filter(sf_ssn_sites, cmplx_desc == .x)) +
    wacolors::scale_color_wa_c("puget") +
    ggspatial::annotation_scale() +
    theme(axis.text = element_blank())
  ) |>  
  wrap_plots(nrow = 3, guides = "collect")

```

### sites: bankfull vs DA

measured bankfull width shows expected clear relationship with DA (roughly loglinear perhaps still slightly exponential for some)

```{r gg_ssn_edges_bankfull_vs_DA}
map(
  c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
  ,
  ~ggplot() +
    geom_point(
      data = ssn_edges |> 
        filter(cmplx_desc == .x, imw_sampled == "with site") |> 
        mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5)))
      ,
      aes(dasqkm_tot, bankfull_width_mean, fill = slope_f), alpha = 1, shape = 24, size = 2, color = "black",
      show.legend = T
    ) +
    scale_x_log10(
      name = "Reach DA (km^2)",
      limits = c(0.01, 100),
      breaks = scales::breaks_log(), 
      labels = scales::label_log()
    ) +
    scale_y_continuous(name = "Mean bankfull width", limits = c(0, 22)) +
    scale_color_manual(values = c("lightblue","darkblue","tan","orange"),
                       aesthetics = c("color","fill")
    ) +
    guides(color = guide_colorsteps(title = "Avg. reach slope"),
           fill = guide_none()) +
    theme(legend.position = "bottom") +
    facet_wrap(~strm, nrow = 1) +
    labs(subtitle = .x)
) |> 
  wrap_plots(nrow = 3, guides = "collect") & 
  theme(legend.position = "bottom")

ggsave("f_ssn_edges_bankfull_DA.png", width = 9, height = 11, dpi = 120, bg = "white")  
```

### sites: VLWD mean

but average (through years) very large wood shows no clear reln to DA

Fox & Bolton Table 1: >80pieces/mile --> 100*(80/1609) --> ~5 pieces/100m?
But Table 4 (and Fig 6), WWa by bankfull width class:
0-6m: 26-29-38
6-30: 29-52-63
30-100: 57-106-208

```{r gg_ssn_edges_vlwd100_mean_vs_DA}
#range(na.omit(ssn_edges$vlwd_per100_mean))

map(
  c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
  ,
  ~ggplot() +
    geom_point(
      data = ssn_edges |> 
        filter(cmplx_desc == .x, imw_sampled == "with site") |> 
        mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5)))
      ,
      aes(dasqkm_tot, vlwd_per100_mean, fill = slope_f), alpha = 1, shape = 24, size = 2, color = "black",
      show.legend = T
    ) +
    # scale_x_log10(
    #   name = "Reach DA (km^2)",
    #   limits = c(0.01, 100),
    #   breaks = scales::breaks_log(), 
    #   labels = scales::label_log()
    # ) +
    scale_y_continuous(name = "VLWD100", limits = c(0,40)) +
    scale_color_manual(values = c("lightblue","darkblue","tan","orange"),
                       aesthetics = c("color","fill")
    ) +
    guides(color = guide_colorsteps(title = "Avg. reach slope"),
           fill = guide_none()) +
    annotate("segment", x=-Inf, xend=Inf, y=-Inf, yend=-Inf) +
    annotate("segment", x=-Inf, xend=-Inf, y=-Inf, yend=Inf) +
    theme(legend.position = "bottom") +
    facet_wrap(~strm, nrow = 1) +
    labs(subtitle = .x)
) |> 
  wrap_plots(nrow = 3, guides = "collect") & 
  theme(legend.position = "bottom")

ggsave("f_ssn_edges_vlwd_mean_DA.png", width = 9, height = 11, dpi = 120, bg = "white")  
```

and average (through years) very large wood has complex reln to slope if any 

```{r gg_ssn_edges_vlwd100_mean_vs_slope}
#range(na.omit(ssn_edges$slope))

map(
  c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
  ,
  ~ggplot() +
    geom_point(
      data = ssn_edges |> 
        filter(cmplx_desc == .x, imw_sampled == "with site") |> 
        mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5)))
      ,
      aes(slope, vlwd_per100_mean, fill = slope_f), alpha = 1, shape = 24, size = 2, color = "black",
      show.legend = T
    ) +
    scale_x_continuous(
      name = "Reach slope"
      #, limits = c(0, 0.4),
    ) +
    scale_y_continuous(name = "VLWD100", limits = c(0,40)) +
    scale_color_manual(values = c("lightblue","darkblue","tan","orange"),
                       aesthetics = c("color","fill")
    ) +
    guides(color = guide_colorsteps(title = "Avg. reach slope"),
           fill = guide_none()) +
    theme(legend.position = "bottom") +
    facet_wrap(~strm, nrow = 1
               , scales = "free_x"
               ) +
    labs(subtitle = .x)
) |> 
  wrap_plots(nrow = 3, guides = "collect") & 
  theme(legend.position = "bottom")

ggsave("f_ssn_edges_vlwd_mean_slope.png", width = 9, height = 11, dpi = 120, bg = "white")  
```

### sites: VLWD CV

coef of var in VLWD vs DA seems inconsistent among streams and complexes? 

```{r gg_ssn_edges_vlwd100_CV_vs_DA}
map(
  c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
  ,
  ~ggplot() +
    geom_point(
      data = ssn_edges |> 
        filter(cmplx_desc == .x, imw_sampled == "with site") |> 
        mutate(
          slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5))
          ,
          vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean
          )
      ,
      aes(dasqkm_tot, vlwd_per100_cv, fill = slope_f), alpha = 1, shape = 24, size = 2, color = "black",
      show.legend = T
    ) +
    geom_hline(yintercept = 1, linetype = 2) +
    # scale_x_log10(
    #   name = "Reach DA (km^2)",
    #   limits = c(0.1, 100),
    #   breaks = scales::breaks_log(), 
    #   labels = scales::label_log()
    # ) +
    scale_y_continuous(name = "VLWD100 CV") +
    scale_color_manual(values = c("lightblue","darkblue","tan","orange"),
                       aesthetics = c("color","fill")
    ) +
    guides(color = guide_colorsteps(title = "Avg. reach slope"),
           fill = guide_none()) +
    annotate("segment", x=-Inf, xend=Inf, y=-Inf, yend=-Inf) +
    annotate("segment", x=-Inf, xend=-Inf, y=-Inf, yend=Inf) +
    theme(legend.position = "bottom") +
    facet_wrap(~strm, nrow = 1) +
    #facet_wrap(dasqkm_tot > 10 ~ strm, nrow = 1, scales = "free_x") +
    labs(subtitle = .x)
) |> 
  wrap_plots(nrow = 3, guides = "collect") & 
  theme(legend.position = "bottom")

#ggsave("f_ssn_edges_vlwd_cv_DA.png", width = 9, height = 11, dpi = 120, bg = "white")  
```

arguably more reln for VLWD CV vs slope?

```{r gg_ssn_edges_vlwd100_CV_vs_slope}
map(
  c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
  ,
  ~ggplot() +
    geom_point(
      data = ssn_edges |> 
        filter(cmplx_desc == .x, imw_sampled == "with site") |> 
        mutate(
          slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5))
          ,
          vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean
          )
      ,
      aes(slope, vlwd_per100_cv, fill = slope_f), alpha = 1, shape = 24, size = 2, color = "black",
      show.legend = T
    ) +
    scale_x_continuous(
      name = "Reach slope"
      , limits = c(0, 0.2)
    ) +
    scale_y_continuous(name = "VLWD100 CV") +
    scale_color_manual(values = c("lightblue","darkblue","tan","orange"),
                       aesthetics = c("color","fill")
    ) +
    guides(color = guide_colorsteps(title = "Avg. reach slope"),
           fill = guide_none()) +
    theme(legend.position = "bottom") +
    facet_wrap(~strm, nrow = 1
               #, scales = "free_x"
               ) +
    labs(subtitle = .x)
) |> 
  wrap_plots(nrow = 3, guides = "collect") + 
  plot_annotation(subtitle = "Excluding 7 sites slope > 0.2") & 
  theme(legend.position = "bottom")

ggsave("f_ssn_edges_vlwd_cv_slope.png", width = 9, height = 11, dpi = 120, bg = "white")
```

overlaying streams does not especially clarify any univariate reln, linear or otherwise

```{r gg_ssn_vlwd100_CV_single_panel}
ssn_edges |> 
  filter(imw_sampled == "with site") |> 
  mutate(
    slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5))
    ,
    vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean
  ) |> 
  ggplot(mapping = aes(
#    dasqkm_tot, vlwd_per100_cv,
    slope, vlwd_per100_cv,
    color = strm
  )) +
  geom_smooth(se=F) +
  geom_point(alpha = 1, shape = 17, size = 1.5, show.legend = T) +
   # scale_x_log10(
   #    name = "Reach DA (km^2)",
   #    limits = c(0.01, 100),
   #    breaks = scales::breaks_log(), 
   #    labels = scales::label_log()
   #  ) + 
  scale_x_continuous(
    name = "Reach slope" #, limits = c(0, 0.05)
  ) +
  scale_color_manual(values = pal_strm)


ssn_edges |> 
  filter(imw_sampled == "with site") |> 
  mutate(vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean) |> 
  ggplot() + 
  #stat_ecdf(aes(vlwd_per100_cv, color = cmplx_strm), linewidth = 1.5) +
  ggridges::geom_density_ridges(aes(vlwd_per100_cv, cmplx_strm, color = cmplx_strm, fill = cmplx_strm)) +
  geom_vline(xintercept = c(0.5, 1)) +
  scale_color_manual(values = pal_cmplx_strm, aesthetics = c("color","fill"))

```

relative to CV > 0.75

  - Deep: 2 sites headwaters, 1 near outlet
  - WTwin: 4 hdwtr, 2 outlet
  - ETwin: 5 all above lower mainstem, 3 on E fork
  - Stavis: 2 hdwtr, 1 mainstem near 4 tribs, 1 outlet
  - Seabeck: 3 hdwtr, 7 lower mainstem and outlet
  - BBC: 3 hdwtr (above Symington), 1 outlet
  - LA: 3 hdwtr, 1 outlet
  - Mill: 3 lower main and outlet
  - Abe: upper resto sites
  - Germ: 5 hdwter, 1 mid/lower mainstem

```{r gg_ssn_vlwd100_CV_map}

gg_sf_cv <- map(
  c("Straits of Juan de Fuca", "Hood Canal", "Lower Columbia")
  ,
  ~ggplot() +
    geom_sf(data = filter(sf_ssn_edges, cmplx_desc == .x), aes(color = strm), linewidth = 0.5) +
    geom_sf(
      data = filter(sf_ssn_sites, cmplx_desc == .x) |> 
        mutate(vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean)
      , 
      #aes(size = vlwd_per100_cv, fill = strm),
      aes(size = vlwd_per100_cv, fill = strm, alpha = vlwd_per100_cv),
      #alpha = 0.7, 
      shape = 24, color = "black",
      ) +
    scale_color_manual(values = pal_strm, aesthetics = c("color","fill")) +
    scale_alpha_binned(breaks = c(0, 0.5, 0.75, 2.5) ) +
    scale_size_binned_area(
      breaks = c(0, 0.5, 0.75, 2.5), 
      #breaks = c(0, 0.75), 
      limits = c(0,2.5)
      ) +
    guides(alpha = guide_none()) +
    ggspatial::annotation_scale() +
    theme(axis.text = element_blank())
  )

wrap_plots(gg_sf_cv) + 
  plot_layout(guides ="collect", widths = c(0.6,0.4),
              design = "
              AC
              BC")

ggsave("f_ssn_sites_gg_sf_cv.png", width = 11, height = 9, bg = "white")
```


### corrr

nicely displays that bankfull width has (expected) strong positive relationship with drainage area and moderate negative reln with slope
BUT 
  - VLWD mean
    - DA: no reln outside Mill Ck
    - elev: moderately positive in LC (signif in Abe and Mill) and W Twin but neg in BBC and Stavis
    - slope: mostly weakly positive
    - bankfull: mix of weak pos/neg and nothing
  - VLWD CV
    - DA: no reln
    - elev: no reln other than weakly pos in WTwin
    - slope: mix of moderately pos/neg
      - pos: ETwin (signif), WTwin
      - neg: Mill (signif), Seabeck (signif)
    - bankfull: mostly no reln but Abe moderately pos (signif)
    - vlwd_mean: mix
      - weakly pos in Deep, no reln in E or WTwin
      - strongly neg (lower variation with higher density) in Seabeck, BBC and Mill
      - weakly neg nonsignif in Stavis and Germany

```{r ssn_sites_ggpairs}
# ssn_sites |> 
#   ggplot(aes(vlwd_per100_sd, vlwd_per100_cv, color = cmplx_strm)) + 
#   geom_point() + scale_color_manual(values = pal_cmplx_strm) +
#   facet_wrap(~cmplx_desc)

# #among-response corr?
# #expected clear pos reln for sd ~ mean
# #some strong neg for cv ~ mean
# #but cv not sharply reln to sd...
# ssn_sites |>
#   select(cmplx_desc, cmplx_strm, starts_with("vlwd")) |> 
#   GGally::ggpairs(
#     mapping = aes(color = cmplx_strm, alpha = 0.8),
#     columns = c(3:5),
#     upper = list(continuous = GGally::wrap("cor", method = "spearman", digits = 2))  
#     ) +
#   scale_color_manual(values = pal_cmplx_strm)

#response-pred
ssn_sites |> 
  GGally::ggpairs(
    mapping = aes(color = strm, alpha = 0.8),
    columns = c(7:11,13),
    upper = list(continuous = GGally::wrap("cor", method = "spearman", digits = 2))
  ) +
  scale_color_manual(values = as.vector(pal_strm), aesthetics = c("color","fill"))

ggsave("f_ssn_sites_ggpairs_spearman.png", width = 10, height = 10, dpi = 120, bg = "white")
```

```{r ssn_sites_corrr}
ssn_sites_cor <- ssn_sites |>
  select(cmplx_strm, site, dasqkm_tot:vlwd_per100_mean, vlwd_per100_cv) |> 
  split(~cmplx_strm) |> 
  map(
    ~.x |> 
      corrr::correlate(method = "spearman", use = "complete.obs") |> 
      #corrr::rearrange() |> 
      corrr::shave() |> 
      corrr::stretch(na.rm = T, remove.dups = T) |> 
      mutate(cmplx_strm = .x$cmplx_strm[1])
  ) |> 
  bind_rows() |> 
  filter(
    str_detect(y, "mean|cv")
  )
```

```{r gt_ssn_sites_corrr}
bind_rows(
  ssn_sites_cor |> 
    filter(y == "bankfull_width_mean") |> 
    pivot_wider(names_from = x, values_from = r)
  ,
  ssn_sites_cor |> 
    filter(y == "vlwd_per100_mean") |> 
    pivot_wider(names_from = x, values_from = r)
  ,
  ssn_sites_cor |> 
    filter(y == "vlwd_per100_cv") |> 
    pivot_wider(names_from = x, values_from = r)
) |> 
  gt(groupname_col = "y", rowname_col = "cmplx_strm") |> 
  fmt_number(decimals = 2) |> 
  sub_missing() |> 
  # # tab_style_body(
  # #   columns = where(is.numeric),
  # #   style = cell_text(weight = "bold"),
  # #   fn = \(x) abs(x) > 0.5
  # # )
  # tab_style_body(
  #   columns = where(is.numeric),
  #   style = cell_fill("tan"),
  #   fn = \(x) abs(x) > 0.3 & abs(x) < 0.5
  # ) |> 
  # tab_style_body(
  #   columns = where(is.numeric),
  #   style = cell_fill("orange"),
  #   fn = \(x) abs(x) > 0.5 & abs(x) < 0.7
  # )
  data_color(
    columns = where(is.numeric), 
    method = "bin", 
    bins = c(-1,-0.7,-0.5,-0.3,
             0.3, 0.5, 0.7, 1)
    , palette = "PuOr"
    
  )


```


### older

```{r d_gg_gt}
d <- as_tibble(sf_ssn_edges) |> 
  select(cmplx_strm, strm, NHDPlusID, dasqkm_tot, elev_min, slope) |> 
  left_join(
    as_tibble(sf_ssn_sites) |> 
      distinct(NHDPlusID, .keep_all = T) |> #no effect but to confirm 1 reach per site
      select(NHDPlusID, site),
    by = "NHDPlusID"
  ) |> 
  mutate(imw_sampled = if_else(!is.na(site), "with site", "without site"))

d_gt <- d |> 
  summarise(
    n = n(),
    across(
      c(da = dasqkm_tot, elev = elev_min, slope), 
      list(min = ~min(.), med = ~median(.), max = ~max(.))
      ), .by = c(cmplx_strm, strm, imw_sampled)
  ) |> 
  mutate(n_pct = n / sum(n), .by = strm) |> 
  select(strm, imw_sampled, n, n_pct, everything()) |> 
  arrange(cmplx_strm, strm, imw_sampled) 
```

```{r gt_reach_da_elev_slope}

d_gt |> 
  gt(groupname_col = "cmplx_strm", rowname_col = "imw_sampled") |> 
  cols_label_with(fn = ~str_remove(., "da_|elev_|slope_")) |> 
  tab_spanner(label = "NHDplusHR reach \nDrainage area", columns = contains("da_")) |> 
  tab_spanner(label = "NHDplusHR reach \nMin. elevation", columns = contains("elev_")) |> 
  tab_spanner(label = "NHDplusHR reach \nSlope", columns = contains("slope_")) |> 
  #tab_style(style = cell_borders("right"), locations = cells_body("n_pct")) |> 
  tab_style(style = cell_borders("left"), locations = cells_body(contains("_min"))) |> 
  # tab_style(style = cell_fill(color = pal_strm["Mill Creek"], alpha = 0.7), locations = cells_body(rows = strm == "Mill Creek" & imw_sampled == "with site")) |> 
  # tab_style(style = cell_fill(color = pal_strm["Abernathy Creek"], alpha = 0.7), locations = cells_body(rows = strm == "Abernathy Creek" & imw_sampled == "with site")) |> 
  # tab_style(style = cell_fill(color = pal_strm["Germany Creek"], alpha = 0.7), locations = cells_body(rows = strm == "Germany Creek" & imw_sampled == "with site")) |> 
  tab_style(
    style = cell_text(weight = "bold"),
    locations = map(
      5:13,
      ~cells_body(columns = .x, rows = which.max(unlist(d_gt[,.x])))
    )
  ) |> 
  fmt_percent("n_pct", decimals = 1) |> 
  fmt_number(c("da_min"), decimals = 3) |> 
  fmt_number(c("da_med"), decimals = 2) |> 
  fmt_number(c("da_max"), decimals = 0) |> 
  fmt_number(contains("elev_"), decimals = 0) |> 
  fmt_number(c("slope_min"), decimals = 5) |> 
  fmt_number(c("slope_med","slope_max"), decimals = 2)

```

```{r gg_reach_da_elev_slope}

{  
  ggplot() +
    geom_point(
      data = d |> 
        filter(imw_sampled == "without site") |> 
        mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5)))
      ,
      aes(dasqkm_tot, elev_min, color = slope_f), alpha = 0.8, shape = 20, size = 0.5,
      show.legend = F
    ) +  
    geom_point(
      data = d |> 
        filter(imw_sampled == "with site") |> 
        mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5)))
      ,
      aes(dasqkm_tot, elev_min, fill = slope_f), alpha = 1, shape = 24, size = 2, color = "black",
      show.legend = F
    ) +
    geom_hline(yintercept = 1, color = "#ADD8E6", linetype = 2) + #linewidth = 0.5
    geom_hline(yintercept = 200, color = "#A45DEC", linetype = 2) + #linewidth = 0.5
    geom_hline(yintercept = 400, color = "#BF4CA0", linetype = 2) + #linewidth = 0.5
    geom_hline(yintercept = 600, color = "#FFA500", linetype = 2) + #linewidth = 0.5
    scale_x_log10(
      breaks = scales::breaks_log(), 
      labels = scales::label_log()
    ) +
    scale_color_manual(values = c("lightblue","darkblue","tan","orange"), aesthetics = c("color","fill")) +
    scale_alpha_manual(values = c(1, 0.5)) +
    scale_shape_manual(values = c(17, 20)) +
    scale_size_manual(values = c(2, 0.6)) +
    facet_wrap(~strm, nrow = 1) +
    labs(
      x = "Reach DA (km^2)", y = "Reach min. elev. (m)"
    )
  } / {
    sf_ssn_lc_edges |> 
      select(strm, NHDPlusID, dasqkm_tot, elev_min, slope) |> 
      mutate(elev_f = cut(slope,  breaks = seq(0, 800, by = 200))) |> 
      ggplot() +
      geom_sf(aes(linewidth = dasqkm_tot, color = elev_min)) +
      geom_sf(data = st_centroid(sf_ssn_lc_sites), shape = 17) +
      scale_color_gradientn(name = "Elevation", colours = c("lightblue","purple","orange"), breaks = seq(0, 800, by = 200)) +
      scale_linewidth(limits = c(0,80), range = c(0.4,2)) +
      guides(linewidth = guide_none()) +
      ggspatial::annotation_scale() +
      facet_wrap(~strm, nrow = 1) +
      labs(subtitle = "Reach min. elevation") +
      theme(axis.text = element_text(size = 4))
  } / {
    sf_ssn_lc_edges |> 
      select(strm, NHDPlusID, dasqkm_tot, elev_min, slope) |> 
      mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.2, 1.5))) |> 
      ggplot() +
      geom_sf(aes(linewidth = dasqkm_tot, color = slope_f)) +
      geom_sf(data = st_centroid(sf_ssn_lc_sites), shape = 17) +
      scale_color_manual(name = "Slope", values = c("lightblue","darkblue","tan","orange")) +
      scale_linewidth(limits = c(0,80), range = c(0.4,2)) +
      guides(linewidth = guide_none(), color = guide_colorsteps()) +
      ggspatial::annotation_scale() +
      facet_wrap(~strm, nrow = 1) +
      labs(subtitle = "Reach slope") +
      theme(axis.text = element_text(size = 4))
  } + 
  plot_layout(guides = "collect")

#ggsave("f_LC_reach_da_elev_slope.png", width = 7.5, height = 10, units = "in")

```

```{r ssn_lc_edges_sites_cor}
## enough non-normality to justify Spearman corr

ssn_lc_edges_cor <- as_tibble(sf_ssn_lc_edges) |> 
  filter(!(NHDPlusID %in% sf_ssn_lc_sites$NHDPlusID)) |> 
  select(
    strm, NHDPlusID, 
    dasqkm_tot, elev_min, slope
  ) |> 
  # GGally::ggpairs(
  #   mapping = aes(color = strm, alpha = 0.8),
  #   columns = c(3:5),
  #   upper = list(continuous = GGally::wrap("cor", method = "spearman", digits = 2))
  #   ) +
  # scale_color_manual(values = as.vector(pal_strm[5:7]), aesthetics = c("color","fill"))
  split(~strm) |> 
  map(
    ~.x |> 
      corrr::correlate(method = "spearman", use = "complete.obs") |> 
      #corrr::rearrange() |> 
      corrr::shave() |> 
      mutate(strm = .x$strm[1])
  )


ssn_lc_sites_cor <- as_tibble(sf_ssn_lc_sites) |> 
  select(
    strm, site, NHDPlusID, 
    ends_with("_med"),
    lwd100_cv = lwd100_years_cv,
    length_km:VEMA,
    #following initial EDA
    -dasqkm_cat, -length_km, -elev_max, -VEMA, -QEMA
  ) |> 
  
# #nice supp plot...?
#   GGally::ggpairs(
#     mapping = aes(color = strm, alpha = 0.8), 
#     columns = c(9:11,4), 
#     upper = list(continuous = GGally::wrap("cor", method = "spearman", digits = 2))
#     ) + 
#   scale_color_manual(values = as.vector(pal_strm[5:7]), aesthetics = c("color","fill"))

  # pivot_longer(-c(strm, site, NHDPlusID)) |> 
  # filter(str_detect(name, "dasqkm|elev|slope|bnk")) |> 
  # # ggplot() +
  # # geom_boxplot(aes(value, strm, color = strm), varwidth = T) + facet_wrap(~name, scales = "free")
  # # geom_qq_line(aes(sample = value, color = strm)) + geom_qq(aes(sample = value, color = strm)) + facet_wrap(~name, scales = "free")
  # summarise(
  #   across(
  #     value,
  #     list(
  #       shap = ~shapiro.test(.)$p.value,
  #       skew = ~e1071::skewness(.)
  #     )), .by = c(strm, name))

  split(~strm) |> 
  map(
    ~.x |> 
      corrr::correlate(method = "spearman", use = "complete.obs") |> 
      #corrr::rearrange() |> 
      corrr::shave() |> 
      mutate(strm = .x$strm[1])
  )

# #everything, used in initial screening
# ssn_lc_sites_cor |>
#   map(~.x |>
#         select(-strm) |>
#         corrr::rplot(print_cor = T) +
#         scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
#         wacolors::scale_color_wa_c("vantage", limits = c(-1,1), reverse = T) +
#         labs(subtitle = .x$strm[1])
#   ) |>
#   wrap_plots(guides = "collect")

```

```{r gt_ssn_lc_sites_cor_indep}
#| label: tbl-lc_cor_indep

# ssn_lc_sites_cor |> 
#   map(
#     ~.x |> 
#       # select(term, dasqkm_tot, elev_min, slope, bnkwdth_p50_med) |> 
#       # corrr::stretch() |> drop_na(r) |> filter(str_detect(y, "dasqkm|elev|slope|bnkwdth"))
#       select(strm, term, 
#              `Bankfull width` = bnkwdth_p50_med,
#              `Drainage area` = dasqkm_tot,
#              Elevation = elev_min
#       ) |> 
#       filter(str_detect(term, "dasqkm|elev|slope"))
#   ) |> 
#   bind_rows() |> 
#   mutate(
#         term = case_when(
#           term == "bnkwdth_p50_med" ~ "Bankfull width",
#           term == "dasqkm_tot" ~ "Drainage area",
#           term == "elev_min" ~ "Elevation",
#           term == "slope" ~ "Slope"
#         )
#       ) |> 
#   gt(
#     groupname_col = "strm", 
#     rowname_col = "term",
#     caption = gt::md("Among-site Spearman correlations  \n physiographic predictors")
#   ) |> 
#   fmt_number() |> 
#   sub_missing() |> 
#   tab_spanner("IMW measured", columns = "Bankfull width") |> 
#   tab_spanner("NHDplus HR", columns = c("Drainage area", "Elevation")) |> 
#   tab_style_body(
#     style = cell_text(color = "red", style = "italic"),
#     fn = function(x) x < 0
#   ) |> 
#   tab_style_body(
#     style = cell_text(weight = "bold"),
#     columns = where(is.numeric),
#     fn = function(x) abs(x) >= 0.5
#   )

full_join(
  ssn_lc_edges_cor |> 
    map(
      ~.x |> 
        select(term, dasqkm_tot, elev_min, slope) |> 
        corrr::stretch(na.rm = T, remove.dups = T) |> 
        mutate(strm = .x$strm[1])
    ) |> 
    bind_rows() |> rename(r_edges = r) 
  ,
  ssn_lc_sites_cor |> 
    map(
      ~.x |> 
        select(term, dasqkm_tot, elev_min, slope, bnkwdth_p50_med) |> 
        corrr::stretch(na.rm = T, remove.dups = T) |> 
        filter(str_detect(y, "dasqkm|elev|slope|bnkwdth")) |> 
        mutate(strm = .x$strm[1])
    ) |> 
    bind_rows() |> rename(r_sites = r) 
  ,
  by = c("strm", "x", "y")
) |> 
  select(strm, x, y, r_edges, r_sites) |> 
  arrange(strm) |> 
  mutate(
    across(
      c(x,y),
      ~case_when(
          . == "bnkwdth_p50_med" ~ "Bankfull width",
          . == "dasqkm_tot" ~ "Drainage area",
          . == "elev_min" ~ "Elevation",
          . == "slope" ~ "Slope"
        )
      )
    ) |>
  unite(col = "measures", x, y, sep = " ~ ") |> 
  gt(
    groupname_col = "strm", 
    rowname_col = "measures",
    caption = gt::md("Among-reach Spearman correlations of physiographic measures")
  ) |> 
  #cols_label_with(fn = ~str_replace(., "r_", "Spearman's r ")) |> 
  cols_label(
    "r_edges" = "NHDplus reaches, no sampling",
    "r_sites" = "Reaches with IMW sampling"
    ) |> 
  fmt_number(columns = starts_with("r_"), decimals = 2) |> 
  sub_missing() |> 
  tab_style_body(
    style = cell_text(color = "red", style = "italic"),
    fn = function(x) x < 0
  ) |> 
  tab_style_body(
    style = cell_text(weight = "bold"),
    columns = where(is.numeric),
    fn = function(x) abs(x) >= 0.5
  ) |> 
  tab_style(
    style = cell_fill(color = "grey90"),
    locations = list(
      cells_stub(rows = str_detect(measures, "Bank")),
      cells_body(rows = str_detect(measures, "Bank"))
    )
  )

```

*NEEDS REWRITE WITH ST & LC*

Germany is a slightly smaller basin, with a maximum drainage area (DA) of ~60km^2 vs ~75km^2 for Mill and Abernathy. 
The minimum and median DA of reaches with IMW sampling was also smallest in Germany. 
The average DA of reaches with IMW sampling was largest in Abernathy (~6.5km^2), but the sampled reach with the largest contributing area in this stream (43km^2) was appreciably smaller than in Mill and Germany Creeks, where IMW sampling included lower mainstem sites near the basin maximum DA.

Abernathy and Germany Creeks both include higher elevation reaches than Mill, and the median reach elevation was more than 50m higher Germany (339m vs 259 in Abernathy and 276 in Mill).
The average and maximum elevation of sampled reaches was appreciably lower than the whole network values in Abernathy, whereas average and maximum elevations were closer to background in Germany and Mill.

Germany had the greatest reach slopes on average, but Abernathy had the steepest reaches. 
The slopes of IMW-sampled reaches in Germany were closer to the (steeper) basin-wide average than in Abernathy, where sampled reaches on average had lower slopes than both the network as a whole and the average in Mill Creek.

Take-aways:
 - sampled reaches captured more of the gradient of DA in Mill and Germany Creek, and more of the gradient of slope in Germany
 - In Abernathy, on average (median) sampled reaches were lower slope and lower elevation and higher DA than both the network background and the other two streams.
  - The steeper, higher elevation headwaters in the NE and the upper portions of the major tributary Cameron Creek had lower site density; inference in these areas carries greater uncertainty


The expected negative Spearman correlation of elevation and DA (i.e., lower elevation with larger DA) was strongest in Mill (-0.77) and moderate in Germany (-0.56) and Abernathy (-0.46), based on NHDplusHR values at reaches with IMW sampling. These correlations were consistent with and stronger than those for the full set of reaches, which included numerous low-order tributaries at lower elevations. 

Slope at IMW-sampled reaches was strongly negatively correlated with DA in Germany and Abernathy Creeks (-0.76 and -0.58 respectively), and these relationships were consistent with (Abernathy) and stronger than those for the full set of reaches. In contrast, the pattern of lower slopes at larger DA was weaker in Mill Creek sampled reaches (-0.25), despite a similarly moderately strong relationship for the full basin (-0.55). 

Relationships between reach slope and elevation differed among basins and within streams between sampled and background reaches. In sampled reaches in Mill Creek, slope was uncorrelated with elevation, in contrast with the weak (and somewhat unusual) negative basin-wide relationship indicating low slopes at higher elevations (0.01 vs -0.22). The sampled reaches in Abernathy Creek lacked the moderately strong positive correlation that was present across the full set of reaches (0.03 vs 0.45), indicating no tendency for higher elevation sites to be steeper. In Germany Creek, the positive correlation at sampled reaches represented a moderate strengthening of the weakly positive relationship basin-wide (0.55 vs 0.12). 

Characteristic channel width at IMW sites, measured as the median through years of the per-year median bankfull width of per-site transects, was strongly positively correlated with drainage area in all LC networks and strongly so in Mill Creek. The expected negative correlation with elevation (i.e., narrower where higher) was also moderately strong in all 3 streams. A negative correlation of width with slope (i.e., narrower where steeper) was moderately strong in the sampled reaches of Germany Creek but relatively weak in both of the other streams.


Taken together, these different relationships... in model fitting.


## SSN fitting

```{r fit_ssn_glm_wrapper}
fit_ssn_glm <- function(ssn_strm, lhs = "vlwd_per100_sd", rhs = "dasqkm_tot + elev_min + slope"){
  SSN2::ssn_glm(
    formula = as.formula(paste(lhs, "~", rhs)),
    ssn.object = ssn_strm,
    family = "Gamma", 
    tailup_type = "exponential",
    taildown_type = "none",
    euclid_type = "gaussian",
    additive = "afvArea"
  ) 
} 

```

```{r ssn_vlwd_cv}
#note above how cv and sd have mixed reln across streams...
f_sd <- fit_ssn_glm(ssns$`171100210302_ETwin_55000800078543`, lhs = "vlwd_per100_sd", rhs = "dasqkm_tot + elev_min + slope")
f_cv <- fit_ssn_glm(ssns$`171100210302_ETwin_55000800078543`, lhs = "(vlwd_per100_sd / vlwd_per100_mean)", rhs = "dasqkm_tot + elev_min + slope")

filter(sf_ssn_sites, str_detect(strm, "East")) |> 
  mutate(vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean) |> 
  select(cmplx_strm, site, dasqkm_tot, vlwd_per100_sd, vlwd_per100_cv) |> 
  #ggplot(aes(vlwd_per100_sd, vlwd_per100_cv)) + geom_point()
  pivot_longer(cols = starts_with("vlwd")) |> 
  #ggplot(aes(dasqkm_tot, value, color = name)) + geom_point() + geom_smooth(method = "lm") + facet_wrap(~name, scales = "free_y")
  split(~name) |> 
  map(
    ~ggplot(.x) + 
      geom_sf(aes(size = value, color = value)) +
      scale_color_gradient(low = "yellow", high = "purple") +
      facet_wrap(~name)
  ) |> 
  wrap_plots(nrow = 1)

summary(f_sd)
summary(f_cv)
  

ssn_vlwd_cv <- map(
  ssns, ~fit_ssn_glm(.x, lhs = "(vlwd_per100_sd / vlwd_per100_mean)", rhs = "dasqkm_tot + elev_min + slope")
  )

gg_sf_cv[[1]]
gg_sf_cv[[2]]
gg_sf_cv[[3]]

map(ssn_vlwd_cv, summary)
map(ssn_vlwd_cv, 
    ~broom::glance(.x) |> mutate(strm = .x$ssn.object$obs$strm[1])
    ) |> 
  bind_rows() |> arrange(pseudo.r.squared)

map(ssn_vlwd_cv, 
    ~broom::tidy(.x, conf.int = T) |> mutate(strm = .x$ssn.object$obs$strm[1])
    )  |> 
  bind_rows() |> 
  filter(p.value < 0.1, term != "(Intercept)")

```

```{r ssn_obs}
ssn_obs <- map(
  ssns, 
  ~as_tibble(.x$obs) |> 
    mutate(
      vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean,
      lon = st_coordinates(geom)[,1],
      lat = st_coordinates(geom)[,2]
    ) |> 
    select(
      cmplx_abrv, cmplx_desc, cmplx_strm, strm, NHDPlusID, site,
      bankfull_width_mean,
      starts_with("vlwd"), lon, lat, dasqkm_tot, elev_min, slope, upDist, afvArea
      )
)
```

```{r rf_cv}
rf_cv <- map(
  ssn_obs,
  \(df) {
    f <- parsnip::rand_forest(
    mode = "regression", #try censored?
    trees = 200, min_n = 1
    ) |> 
    parsnip::set_engine(engine = "ranger", importance = "impurity") |> 
    parsnip::fit(
      formula = vlwd_per100_cv ~ lon + lat + dasqkm_tot + elev_min + slope + upDist + afvArea, 
      data = df
    )
    f$cmplx_strm <- df$cmplx_strm[1]
    return(f)
  })

map(rf_cv, ~.x |> vip::vi() |> mutate(cmplx_strm = .x$cmplx_strm))
map(rf_cv, ~.x |> vip::vip(geom = "point") + labs(subtitle = .x$cmplx_strm)) |> 
  wrap_plots()
  
```



```{r ssn_bank_mean}
#reference streams
ssn_bank_mean <- map(
  ssns[c(3,7,9)]
  ,
  ~fit_ssn_glm(.x, lhs = "bankfull_width_mean", rhs = "dasqkm_tot + elev_min + slope")
  )
ssn_bank_mean_noDA <- map(
  ssns[c(3,7,9)]
  ,
  ~fit_ssn_glm(.x, lhs = "bankfull_width_mean", rhs = "elev_min + slope")
  )

#clearly strong fits: good pseudoR2, signif preds in all 3
map(ssn_bank_mean, summary)
map(ssn_bank_mean, ~broom::glance(.x) |> mutate(strm = .x$ssn.object$obs$strm[1])) |> 
  bind_rows() |> arrange(pseudo.r.squared)
map(ssn_bank_mean, ~broom::tidy(.x, conf.int = T) |> mutate(strm = .x$ssn.object$obs$strm[1])) |> 
  bind_rows() |> 
  filter(p.value < 0.1, term != "(Intercept)")

map(ssn_bank_mean, loocv)
map(ssn_bank_mean_noDA, loocv) #largely similar, RMSPE worse in Mill & Stavis, slightly better WTwin 



#conditional inference trees
cit_bnk <- map(
  ssn_obs[c(3,7,9)],
  \(df){
    d <- df |> select(bankfull_width_mean, lon, lat, dasqkm_tot, elev_min, slope, upDist
                      #, afvArea
                      )
    ct <- party::ctree(
      bankfull_width_mean ~ ., data = d,
      controls = party::ctree_control(testtype = "Univariate", minsplit = 3, minbucket = 3)
      )
    return(list(ct = ct, strm = df$strm[1]))
  }
) 

cit_bnk |> map(\(ct) {plot(ct$ct, main = ct$strm)})
tibble(
ssn = ssn_bank_mean$`170800030605_Mill_55000300323139` |> fitted()
,
cit = cit_bnk$`170800030605_Mill_55000300323139`$ct |>predict()
)


```

```{r ssn_vlwd_mean}
#reference streams
ssn_vlwd_mean <- map(
  ssns[c(3,7,9)]
  ,
  ~fit_ssn_glm(.x, lhs = "vlwd_per100_mean", rhs = "dasqkm_tot + elev_min + slope")
  )

map(ssn_vlwd_mean, summary)
map(ssn_vlwd_mean, ~broom::glance(.x) |> mutate(strm = .x$ssn.object$obs$strm[1])) |> 
  bind_rows() |> arrange(pseudo.r.squared)
map(ssn_vlwd_mean, ~broom::tidy(.x, conf.int = T) |> mutate(strm = .x$ssn.object$obs$strm[1]))  |> 
  bind_rows() |> 
  filter(p.value < 0.1, term != "(Intercept)")

#conditional inference trees for mean density
map(
  ssn_obs[c(3,7,9)],
  \(df){
    d <- df |> select(vlwd_per100_mean, lon, lat, dasqkm_tot, elev_min, slope, upDist
                      #, afvArea
                      )
    ct <- party::ctree(
      vlwd_per100_mean ~ ., data = d,
      controls = party::ctree_control(testtype = "Univariate", minsplit = 3, minbucket = 3)
      )
    return(list(ct = ct, strm = df$strm[1]))
  }
) |> map(\(ct) {plot(ct$ct, main = ct$strm)})

```

### ref only

main takeaway: more cleaning and checking to ensure wood counts are valid and sites are assigned to correct reach...
MIL015 appears assigned wrong DA based on wider bankfull than MIL020
DEW695 has small DA, large bankfull
looking back at saved bankfull~DA for all streams suggests 1 each in ABE and GER and probably LA

```{r gg_ssn_vlwd100_ref_only}
map(
  c("West","Stavis","Mill")
  ,
  ~ggplot() +
    geom_sf(data = filter(sf_ssn_edges, str_detect(cmplx_strm, .x)),
            aes(color = strm, linewidth = dasqkm_tot)) +
    geom_sf(
      data = filter(sf_ssn_sites, str_detect(cmplx_strm, .x)) |> 
        filter(
          site != "DEW016" #bad val in 2008
        ) |> 
        mutate(vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean)
      , 
      aes(size = vlwd_per100_mean, fill = strm
          #, alpha = vlwd_per100_mean
          ),
      shape = 24, color = "black",
      ) +
    scale_linewidth(limits = c(0,80)) +
    scale_size_binned_area(limits = c(0,25)) +
    scale_alpha(limits = c(0,25)) +
    scale_color_manual(values = pal_strm, aesthetics = c("color","fill")) +
    ggspatial::annotation_scale() +
    theme(axis.text = element_blank())
  ) |> 
  wrap_plots(guides = "collect")


ssn_sites_ref <- ssn_sites |> 
  filter(str_detect(strm, "West|Stavis|Mill")) |> 
  #count(strm, slope > 0.1)
  #filter(slope > 0.2) |> pull(site) #"STA002" "DEW178" "DEW016"
  filter(
    site != "DEW016" #bad val in 2008
  ) |> 
  mutate(
    vlwd_per100_cv = vlwd_per100_sd / vlwd_per100_mean
  ) |> 
  select(cmplx_strm, site, 
         dasqkm_tot, elev_min, slope,
         bankfull_width_mean,
         vlwd_per100_mean,
         vlwd_per100_sd,
         vlwd_per100_cv
         ) 

ssn_sites_ref |>
  #filter(slope <= 0.1) |> 
  GGally::ggpairs(
    mapping = aes(color = cmplx_strm, alpha = 0.8),
    columns = c(3:9),
    upper = list(continuous = GGally::wrap("cor", method = "spearman", digits = 2))
  )

ssn_sites_ref |>
  filter(slope <= 0.1) |> 
  pivot_longer(cols = c(dasqkm_tot, elev_min, slope)) |> 
  ggplot(mapping = aes(
    value, vlwd_per100_cv,
    color = cmplx_strm
  )) +
  geom_smooth(se=F) +
  geom_point(alpha = 1, shape = 17, size = 1.5, show.legend = T) +
  scale_color_manual(values = pal_cmplx_strm) +
  facet_wrap(cmplx_strm~name, scales = "free_x")

sf_ssn_sites |> filter(site %in% c("STA002","DEW178","DEW016")) |> mapview::mapview(zcol = "site")
sf_ssn_sites |> filter(str_detect(strm, "West|Stavis|Mill"), site != "DEW016") |> 
  mapview::mapview(zcol = "vlwd_per100_mean")

#full time series ordinated by slope
site_year |> 
  # #DEW016 vlwd_per100 error in 2008? the density > count
  # filter(site == "DEW016") |> select(strm, site, year, tot_srvy_lgth, starts_with("vlwd"))
  # # MIL014 shows decreased tot_survey length starting 2022...and abnormally low count in 2008
  # filter(site == "MIL014") |> select(strm, site, year, tot_srvy_lgth, starts_with("vlwd"))
  filter(str_detect(strm, "West|Stavis|Mill")) |> 
  filter(!(site == "DEW016" & year == 2008)) |> 
  left_join(ssn_sites |> select(site, dasqkm_tot, slope), by = "site") |> 
  split(~cmplx_strm, drop = T) |> 
  map(
    ~.x |> 
      mutate(slope_f = factor(round(slope,4))) |> 
      ggplot(aes(year, vlwd_per100, fill = cmplx_strm, 
                 #alpha = dasqkm_tot, 
                 group = site)) +
      geom_col() +
      scale_fill_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
      facet_wrap(~slope_f, ncol = 1)
  ) |> wrap_plots(guides = "collect")

#MIL015 appears assigned wrong DA based on wider bankfull than MIL020
site_year |> 
  filter(str_detect(strm, "West|Stavis|Mill")) |> 
  filter(!(site == "DEW016" & year == 2008)) |> 
  left_join(ssn_sites |> select(site, dasqkm_tot, slope), by = "site") |> 
  ggplot() +
  geom_tile(aes(year, fct_reorder(site, dasqkm_tot), fill = vlwd_per100)) +
  scale_fill_gradient(low = "yellow", high = "purple") +
  facet_wrap(~cmplx_strm, scales = "free_y")

#MIL015 evident as positive resid outlier
#DEW695 looks 
{ssn_sites_ref |> 
  ggplot(aes(dasqkm_tot, bankfull_width_mean, color = cmplx_strm, label = site)) + geom_point() + scale_color_manual(values = pal_cmplx_strm)
} |> plotly::ggplotly()


#heatmap of survey lengths
site_year |> 
  filter(str_detect(strm, "West|Stavis|Mill")) |> 
  filter(!(site == "DEW016" & year == 2008)) |> 
  #left_join(ssn_sites |> select(site, dasqkm_tot, slope), by = "site") |> 
  ggplot() +
  geom_tile(aes(year, fct_rev(site), fill = tot_srvy_lgth)) +
  geom_text(aes(year, fct_rev(site), label = round(tot_srvy_lgth)), size = 2.5) +
  scale_fill_fermenter(type = "div", breaks = c(0,270,330,700), palette = "PuOr") +
  facet_wrap(~cmplx_strm, scales = "free_y") +
  labs(x = NULL, y = NULL)

  # split(~cmplx_strm, drop = T) |> 
  # lapply(
  #   \(d){
  #     plotly::plot_ly(d,
  #                     type = "bar",
  #                     name = ~site,
  #                     x = ~year, 
  #                     y = ~vlwd_per100
  #                     #,color = ~cmplx_strm
  #     )}
  # ) |> 
  # plotly::subplot(nrows = 3)


```



### full models per basin

prelim takeaway - Mill best of poor fits, DA in Mill only signif covar, substantantial prop var in all 3 in nugget, resid and qq plots esp for Abe and Germ suggest nonlinearity 

would/could fit a model for bankfull on DA and elev and slope then refit LWD on estimated bankfull...

should do CV (AND mean diff?!?) but also could move to RF or GAM or better nonlin structure

```{r fit_glm_ssn_lwd_med}
#in order to fit poisson or negbinom need to rebuild all the way back to `sf_sites_lc <- site_meta_sf`
#resummarizing from site_year$tot_lwd_cnt

ssn_lwd_med <- map(
  ssn, ~fit_ssn_glm(.x, lhs = "lwd100_med", rhs = "dasqkm_tot + elev_min + slope")
  )

map(ssn_lwd_med, summary)
# map(ssn_lwd_med, ~.x$pseudoR2) 
# map(ssn_lwd_med, ~.x$coefficients$fixed)
map(ssn_lwd_med, ~broom::glance(.x) |> mutate(strm = .x$ssn.object$obs$strm[1])) |> bind_rows() |> select(strm, AICc, pseudo.r.squared)

#this seems like something to discuss...
#nugget is largest for all 3, Mill and Abe with appreciable euclid, Mill with the 
map(ssn_lwd_med, ~varcomp(.x) |> mutate(strm = .x$ssn.object$obs$strm[1])) |> list_rbind() |> pivot_wider(names_from = varcomp, values_from = proportion)

#original untransform (logged) mean values by stream
map(ssn, ~as.data.frame.list(round(summary(.x$obs$lwd100_med), 3)) |> 
      mutate(
        logmu = log(Mean),
        strm = .x$obs$strm[1]
        )) |> bind_rows() 

#is RMSPE is in backtransformed (exp) units?
#can examine function to be sure
ssn_lwd_med_loo <- map(ssn_lwd_med,  ~SSN2::loocv(.x))
bind_rows(ssn_lwd_med_loo)


#all confint span 0 except DA in Mill, matching nonsignif
#note "parameters are estimated on the relevant link scale and should be interpreted accordingly"
#so, for example in Mill, 'dasqkm_tot: -0.0188' is the decrease in log average lwd100_med per unit increase in log DA 
#or...the decrease in log average lwd100_med per unit increase in non-log DA 
#so would like to confirm that exp(-0.0188) = 0.981 fewer LWD/100 per each sqkm (just less than 1 fewer piece per additional sqkm?)
map(ssn_lwd_med, ~broom::tidy(.x, conf.int = T) |> mutate(exp_est = exp(estimate)))
#negative rel'n but not linear
ssn_lwd_med$Mill$ssn.object$obs |> ggplot(aes(dasqkm_tot, lwd100_med)) + geom_point() + geom_smooth(se = F)
ssn_lwd_med$Mill$ssn.object$obs |> ggplot(aes(log10(dasqkm_tot), lwd100_med)) + geom_point() + geom_smooth(se = F)

#these do not look good for linear, homoscedastic...
map(ssn, ~.x$obs)
map(ssn_lwd_med, ~tibble(
  #orig = .x$ssn.object$obs$lwd100_med, #same as "obs", just checking
  obs = .x$y, est = .x$fitted$response, res = .x$residuals$response
  ) |> arrange(est))
map(ssn_lwd_med, ~plot(.x, which = 1))

#Q-Q 
map(ssn_lwd_med, ~plot(.x, which = 2))
#Cooks dist
map(ssn_lwd_med, ~plot(.x, which = 4))


```

REDO
maybe these are not especially interesting woodscapes...? but also maybe estimate lwd100_med network-wide then have as pred covar for lwd100_years_cv?
```{r glm_woodscape}
ssn_lwd_med_mill <- fit_ssn_glm(ssn_strm = ssn$Mill, frm = "lwd100_med ~ dasqkm_tot + slope")
#ssn_lwd_med_mill <- fit_ssn_glm(ssn_strm = ssn$Abernathy, frm = "lwd100_med ~ dasqkm_tot + slope")
summary(ssn_lwd_med_mill) #slope not signif, intercept strongly, DA neg est and highly signif (less wood moving downstream)

# SSN2:::predict.ssn_glm(ssn_lwd_med_mill) #pred pts length numeric vector
# SSN2:::predict.ssn_glm(ssn_lwd_med_mill, newdata = "preds") #same

# SSN2:::augment.ssn_glm(ssn_lwd_med_mill) #fitted as sf points
# #sf pred pts with .fitted column added
ssn_lwd_med_mill_pred <- SSN2:::augment.ssn_glm(ssn_lwd_med_mill, newdata = "preds", type = "response")
ssn$Mill$obs$lwd100_med |> summary()
SSN2:::augment.ssn_glm(ssn_lwd_med_mill) |> 
  as_tibble() |> 
  ggplot() + geom_abline(slope = 1) + 
  geom_point(aes(lwd100_med, .fitted, size = dasqkm_tot, color = slope))

ssn_lwd_med_mill_pred$.fitted |> summary() 
ssn_lwd_med_mill_pred |> 
  as_tibble() |> 
  ggplot() + 
  geom_col(aes(x = fct_reorder(NHDPlusID, .fitted, identity), y = .fitted, color = slope))

ggplot() +
  geom_sf(data = ssn$Mill$edges, aes(linewidth = dasqkm_tot), alpha = 0.4, color = "lightblue") +
  geom_sf(
    data = inner_join(
      ssn$Mill$edges,
      as_tibble(ssn_lwd_med_mill_pred) |> select(rid, .fitted) 
      , by = "rid") |> 
      filter(.fitted < quantile(.fitted, p = 0.95))
    , 
    aes(color = .fitted, linewidth = dasqkm_tot)
    #aes(color = cut(.fitted, c(0,1,3,5,10)), linewidth = dasqkm_tot)
  ) +
  wacolors::scale_color_wa_c("footbridge", reverse = T) +
  geom_sf(data = ssn$Mill$obs, 
          aes(
            #color = cut(lwd100_med, c(0,1,3,5,10))
            color = lwd100_med
            ), size = 4)


ssn_lwd_med_mill_pred |>
  mutate(.fitted = cut(.fitted, seq(0,50, by = 10))) |> 
  mapview::mapview(zcol = ".fitted", burst = T)


ssn_lwd_cv_mill <- fit_ssn_glm(ssn_strm = ssn$Mill, frm = "lwd100_years_cv ~ dasqkm_tot + slope")
ssn_lwd_cv_aber <- fit_ssn_glm(ssn_strm = ssn$Abernathy, frm = "lwd100_years_cv ~ dasqkm_tot + slope")

summary(ssn_lwd_cv_mill) #not necessarily terrible, DA weakly signif, slope below 0.1
ssn_lwd_cv_mill$fitted$response |> summary()
SSN2:::augment.ssn_glm(ssn_lwd_cv_mill, type = "response") |> 
  as_tibble() |> 
  ggplot() + geom_abline(slope = 1) + 
  geom_point(aes(lwd100_years_cv, .fitted, size = dasqkm_tot, color = slope))

summary(ssn_lwd_cv_aber) #much worse r2 etc., basically nothing
#so why are fitted so close to obs?
ssn_lwd_cv_aber$fitted$response |> summary()
ssn_lwd_cv_aber$y |> summary()
SSN2:::augment.ssn_glm(ssn_lwd_cv_aber, type = "response") |> 
  as_tibble() |> 
  ggplot() + geom_abline(slope = 1) + 
  geom_point(aes(lwd100_years_cv, .fitted, size = dasqkm_tot, color = slope))

ssn_lwd_cv_mill$residuals$response |> summary()
ssn_lwd_cv_aber$residuals$response |> summary()

ssn_lwd_cv_mill_pred <- ssn_lwd_cv_mill |> SSN2:::augment.ssn_glm(newdata = "preds", type = "response")
ssn_lwd_cv_mill_pred$.fitted |> summary() 

ggplot() +
  geom_sf(data = ssn$Mill$edges, aes(linewidth = dasqkm_tot), alpha = 0.4, color = "lightblue") +
  geom_sf(
    data = inner_join(
      ssn$Mill$edges,
      as_tibble(ssn_lwd_cv_mill_pred) |> select(rid, .fitted) 
      , by = "rid")
    , 
    aes(color = .fitted, linewidth = dasqkm_tot)
  ) +
  wacolors::scale_color_wa_c("forest_fire", reverse = T) +
  geom_sf(data = ssn$Mill$obs, aes(color = lwd100_years_cv), size = 4)
#spatial estimates reflect a pretty clear neg relationship in obs
ggplot(ssn$Mill$obs) + geom_point(aes(lwd100_med, lwd100_years_cv, size = dasqkm_tot, color = slope))
#which is much more complicated in Abernathy
ggplot(ssn$Abernathy$obs) + geom_point(aes(lwd100_med, lwd100_years_cv, size = dasqkm_tot, color = slope))

ssn_lwd_cv_aber_pred <- ssn_lwd_cv_aber |> SSN2:::augment.ssn_glm(newdata = "preds", type = "response")
ssn_lwd_cv_aber_pred$.fitted |> summary() 

ggplot() +
  geom_sf(data = ssn$Abernathy$edges, aes(linewidth = dasqkm_tot), alpha = 0.4, color = "lightblue") +
  geom_sf(
    data = inner_join(
      ssn$Abernathy$edges,
      as_tibble(ssn_lwd_cv_aber_pred) |> select(rid, .fitted) 
      , by = "rid")
    , 
    aes(color = .fitted, linewidth = dasqkm_tot)
  ) +
  wacolors::scale_color_wa_c("forest_fire", reverse = T) +
  geom_sf(data = ssn$Abernathy$obs, aes(color = lwd100_years_cv), size = 4)

#just noticed that snapped startpoints create duplicate pred points
#not really harmful just worth cleaning
as_tibble(ssn_lwd_cv_mill_pred) |> count(rid) |> arrange(desc(n)) |> filter(n>1)
as_tibble(ssn_lwd_cv_aber_pred) |> count(rid) |> arrange(desc(n)) |> filter(n>1)
as_tibble(ssn$Mill$preds$preds) |> count(rid) |> arrange(desc(n)) |> filter(n>1)
as_tibble(ssn$Abernathy$preds$preds) |> count(rid) |> arrange(desc(n)) |> filter(n>1)
```



would like to compare pooled and distinct stream fits...but have to think about how pooling across streams would even work - seems like requires rebuilding using 'netID' to track the 3 edge sets

also think about residuals and whether larger per-site residuals could represent/detect restoration effects...?
call with Jeremy H:  negative resid as 'high priority targets'

can also attempt parsnip/tidymodels approach, but not sure if set_engine will work without some extra plumbing?

what about using SSNbler-prepped attributes but sending into RF-type prediction engine? so using AFV or other topology and/or just bare NHDplusHR but for cleaned networks

```{r parsnipping}
#https://parsnip.tidymodels.org/articles/Examples.html

library(tidymodels)

d_obs <- as_tibble(ssn$Mill$obs) |> 
  mutate(
    lon = st_coordinates(geom)[,1],
    lat = st_coordinates(geom)[,2]
  ) |> 
  select(lwd100_med, lon, lat, dasqkm_tot, elev_min, slope, upDist, afvArea)

d_edges <- ssn$Mill$edges |> 
  mutate(
    pt_start = lwgeom::st_startpoint(geom),
    lon = st_coordinates(pt_start)[,1],
    lat = st_coordinates(pt_start)[,2]
  )

rand_forest(
  mode = "regression", #try censored?
  engine = "ranger",
  trees = 200, min_n = 1
) |> 
  fit(
    formula = lwd100_med ~ ., 
    data = d_obs
  ) |> str()
  predict(d_obs) |> cbind(d_obs$lwd100_med)

```

## HRCD

```{r hrcd_intersection}
gdb <- file.path(dir_data_common, "HRCD.gdb") #also NAD83(HARN)
sf::st_layers(gdb)
hrcd <- sf::st_read(gdb, layer = "HRCD_ChangeLocations") |> #~4gb
  tibble::rowid_to_column("uid")
#subset to anthropogenic change polys with non-zero tree loss
hrcd_anth_loss <- hrcd |> 
  filter(
    CngOrigin != "Natural",
    TreeDecAc > 0
  ) |> 
  select(uid, StartYr, EndYr, TreeDecPct, CngOrigin, CngAgentNm, TreeDecAc, Shape)

#could also get 'whole-stream' HRCD from HUC12s...
#start here with intersection against (buffered?) lines
#union by stream
sf_ssn_edges_strm <- sf_ssn_edges |> group_by(cmplx_strm) |> summarise() 
#then intersect change polys, duplicating if/when multiple streams
sf_ssn_edges_strm_hrcd <- sf_ssn_edges_strm |> 
  st_join(
    hrcd_anth_loss
  )
sf_ssn_edges_strm_300_hrcd <- sf_ssn_edges_strm |> 
  st_buffer(300) |> 
  st_join(
    hrcd_anth_loss
  )

### for unbuffered:
#only 2 change polys that intersect 2 streams
#but looks like only 2015-2017 commonly present across complexes
#LC has newer (end 19, 21) but not older polys (end 09, 11, 13, 15)
### for 300ft buffered:
#17 change polys associated to 2 streams (none more than 2 streams tho)
#same time stanzas, so constraint to 15-17 is appropriate for cross complex comparison
as_tibble(sf_ssn_edges_strm_hrcd) |> 
as_tibble(sf_ssn_edges_strm_300_hrcd) |> 
  #count(uid) |> arrange(desc(n)) |> filter(n>1)
  #count(cmplx_strm, EndYr) |> pivot_wider(names_from = EndYr, values_from = n)
  filter(EndYr == 2017) |> 
  #count(cmplx_strm, StartYr)
  summarise(
    across(TreeDecAc, sum), .by = c(cmplx_strm, CngAgentNm)
  ) |> 
  pivot_wider(names_from = CngAgentNm, values_from = TreeDecAc)

#intersect HRCD with (buffered) line by feature does not explictly account for 'watershed' routing, only 'catchment'
#starting with 300ft for the linestrings with associated sites...
#not all reaches/sites have any HRCD intersection even at 300ft
sf_ssn_edges_sites_300_hrcd <- sf_ssn_edges |> 
  semi_join(
    as_tibble(sf_ssn_sites), by = "NHDPlusID"
  ) |> 
  st_buffer(300) |> 
  st_join(
    hrcd_anth_loss |> 
      filter(EndYr == 2017)
  )  

as_tibble(sf_ssn_edges_sites_300_hrcd) |> 
  filter(EndYr == 2017) |> #also drops non-intersected reaches/sites
  summarise(
    across(TreeDecAc, sum), 
    .by = c(cmplx_strm, NHDPlusID, CngAgentNm)
  ) |> 
  pivot_wider(names_from = CngAgentNm, values_from = TreeDecAc)

#somewhat helpful overlaid on imagery
mapview::mapview(sf_ssn_edges, zcol = "dasqkm_tot", color =  \(n){ grDevices::hcl.colors(n, palette = "Blues", rev = T) }) +
mapview::mapview(sf_ssn_sites, zcol = "vlwd_per100_mean", col.regions =  \(n){ grDevices::hcl.colors(n, palette = "Greens", rev = T) }) +
mapview::mapview(sf_ssn_edges_sites_300_hrcd, zcol = "TreeDecAc", col.regions =  \(n){ grDevices::hcl.colors(n, palette = "YlOrBr", rev = T) })

  
bind_rows(
  as_tibble(sf_ssn_edges_strm_hrcd) |> 
    filter(EndYr == 2017) |> summarise(hrcd_tree_ac = sum(TreeDecAc), .by = c(cmplx_strm)) |> 
    mutate(type_st = "intersect_line")
  ,
  as_tibble(sf_ssn_edges_strm_300_hrcd) |> 
    filter(EndYr == 2017) |> summarise(hrcd_tree_ac = sum(TreeDecAc), .by = c(cmplx_strm)) |> 
    mutate(type_st = "intersect_300ft")
  ,
  as_tibble(sf_ssn_edges_sites_300_hrcd) |> 
    filter(EndYr == 2017) |> summarise(hrcd_tree_ac = sum(TreeDecAc), .by = c(cmplx_strm)) |> 
    mutate(type_st = "IMW_site_reaches")
) |> 
  ggplot() +
  geom_col(aes(hrcd_tree_ac, cmplx_strm, fill = cmplx_strm), show.legend = F) +
  scale_fill_manual(values = pal_cmplx_strm) +
  facet_wrap(~type_st, scales = "free") +
  labs(x = "acres", y = NULL, 
       title = "Total tree loss acres 2015-2017",
       subtitle = "HRCD intersecting NHDPlusHR flowlines, directly & buffered")



as_tibble(sf_ssn_edges_sites_300_hrcd) |> 
  mutate(tree_loss = replace_na(TreeDecAc, 0) |> round(3)) |> 
  summarize(
    across(tree_loss, sum), 
    .by = NHDPlusID
    ) |> 
  left_join(
    as_tibble(sf_ssn_sites) |> 
      select(starts_with("cmplx"), NHDPlusID, site, bankfull_width_mean, lwd_all_per100_mean, vlwd_per100_mean)
    ,
    by = "NHDPlusID"
  ) |> 
  filter(str_detect(cmplx_strm, "West|Stavis|Mill")) |> 
  pivot_longer(cols = ends_with("_mean")) |> 
  ggplot(aes(tree_loss, value, color = cmplx_strm, fill = cmplx_strm, label = site)) +
  geom_point(alpha = 0.5, show.legend = F) +
  scale_fill_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
  facet_wrap(~cmplx_strm + name, scales = "free") +
  labs(x = "tree loss acres", y = "",
       subtitle = "HRCD 2015-17 intersecting 300ft buffer on NHDPlusHR flowlines with IMW sites"
       )


as_tibble(sf_ssn_sites) |> 
  ggplot(aes(bankfull_width_mean, lwd_all_per100_mean, color = cmplx_strm, fill = cmplx_strm)) +
  geom_point(show.legend = F) +
  scale_fill_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
  facet_wrap(~cmplx_strm, scales = "free")


```


## scraps

```{r d_hi_cv_niceplottoworkupmore}
#use residuals rather than abs thresholds?
d_hi_cv <- d |> 
      #filter(lwd100_med > 15 | lwd100_years_cv > 1)
      filter( lwd100_years_cv > 1)

 
d |> 
  ggplot(aes(lwd100_med, lwd100_years_cv, color = strm)) +
  geom_hline(yintercept = c(0.75,1), linewidth = 0.5, alpha = 0.4, linetype = 2) +
  geom_vline(xintercept = 10, linetype = 3) +
  geom_point(alpha = 0.5, show.legend = F) +
  geom_smooth(method = "lm", se = F, show.legend = F) +
  geom_text(
    data = as_tibble(d_hi_cv),
    aes(label = site), hjust = "inward", size = 2, show.legend = F
  ) +
  #geom_smooth(method = "lm")
  scale_color_manual(values = pal_strm) + 
  #facet_wrap(~cmplx_strm)
  facet_wrap(~strm_type + cmplx_strm, ncol = 2)


d |> 
  semi_join(as_tibble(d_hi_cv), by = "site") |> 
  split(~cmplx_desc) |> 
  map(
    ~ggplot(.x) +
      geom_sf(
        data = sf_nhdphr |>
          filter(cmplx_desc == .x$cmplx_desc[1]) |>
          mutate(slope_f = cut(slope,  breaks = c(0, 0.05, 0.1, 0.25, 1.5)))
        ,
        aes(linewidth = dasqkm, color = slope_f), alpha = 0.4
      ) +
      scale_color_manual(values = c("lightblue","darkblue","tan","orange")) +
      scale_linewidth(limits = c(0,80), range = c(0.5,3)) +
      
      geom_sf(
        # aes(size = lwd100_med, shape = lwd100_years_cv_f), 
        # color = if_else(.x$lwd100_years_cv_f, "tomato","grey30")
        size = 2, color =  "tomato"
        #, alpha = 0.5
      ) +
      geom_sf_text(
        aes(label = site), size = 2.5,
        color =  "tomato", vjust = "bottom", nudge_y = 1000
        #, alpha = 0.5
      ) +
      scale_size_area(limits = c(0, 20), breaks = c(0,1,5,10,20)) +
      ggspatial::annotation_scale() +
      labs(x = NULL, y = NULL, subtitle = .x$cmplx_desc[1])
  ) |> 
  wrap_plots(ncol = 1, guides = "collect") -
  { 
    site_year |> 
      semi_join(d_hi_cv, by = "site") |> 
      ggplot(aes(year, lwd100, group = site, color = cmplx_strm)) +
      geom_point() + geom_line(linetype = 3) +
      scale_color_manual(values = pal_cmplx_strm) +
      #facet_wrap(~strm, scales = "free_y")
      facet_wrap(~cmplx_strm+site, scales = "free_y", ncol = 2) +
      labs(
        title = "Large wood density in time at sites with CV > 1", 
        subtitle = "Density is count/100m; note varied y-axis scales")
  } + 
  plot_layout(ncol = 2)


site_year |> filter(site == "STA057") |> pull(lwd100) |> Kendall::MannKendall() |> summary()
site_year |> filter(site == "ABR072") |> pull(lwd100) |> Kendall::MannKendall() |> summary()

y = site_year |> filter(site == "ABR072") |> pull(lwd100)
x = site_year |> filter(site == "ABR072") |> pull(year)
broom::tidy(lm(y ~ x))
summary(lm(y ~ x))$coefficients
site_year |> filter(site == "ABR072") |> 
  summarise(
    lwd100_lm = summary(lm(lwd100 ~ year))$coefficients["year",4]
    ,.by = site
  )

#CV high var not at all necessarily linked with 
#MK monotonic trend
#nor OLS linear time-reg on year
#this is maybe not usable as-is but also maybe interesting/helpful?
#some notes:
#only 6 of 42 MK pval < 0.1 with lm pval > 0.1 ---> signif monoton but nonsignif tvar reg
#tho 16 of 52 lm signif <0.1 have MK pval > 0.1 --> higher proport signif tvar reg that are not monoton
#but generally signif tvar slope est look corr with MK tau
#also
#few signif neg lm slopes in LC, especially relative to HC
#most signif pos lm in Abe, with some in Germ;
site_year |> 
#  semi_join(d_hi_cv, by = "site") |> 
  summarise(
    across(
      c(lwd100), #pct_pools, pct_gravel,
      list(
        q50 = ~median(., na.rm = T),
        cv = ~sd(., na.rm = T) / mean(., na.rm = T),
        mk_tau = ~as.vector(Kendall::MannKendall(.)$tau),
        mk_p = ~as.vector(Kendall::MannKendall(.)$sl)
      )
    )
    ,
    lwd100_lm_est = summary(lm(lwd100 ~ year))$coefficients["year",1],
    lwd100_lm_pval = summary(lm(lwd100 ~ year))$coefficients["year",4],
    ,
    .by = c(cmplx_strm, site)
  ) |> 
  #filter(lwd100_mk_p < 0.1) #how many at least weakly monotonic: 42
  #filter(lwd100_mk_p < 0.1, lwd100_lm_pval > 0.1) #how many of those NOT signif slope: 6
  #filter(lwd100_lm_pval < 0.1) #how many at least weakly tvar signif: 52
  filter(lwd100_lm_pval < 0.1, lwd100_mk_p > 0.1) #how many of those NOT monoton signif: 16
  
  #ggplot(aes(lwd100_cv, lwd100_mk, size = lwd100_q50, color = cmplx_strm)) +
  #ggplot(aes(lwd100_lm_est, lwd100_mk_tau, size = lwd100_q50, color = cmplx_strm)) +
  ggplot(aes(lwd100_lm_est, lwd100_mk_tau, size = lwd100_q50, color = cmplx_strm, alpha = lwd100_lm_pval)) +
  geom_point() +
  scale_color_manual(values = pal_cmplx_strm) +
  scale_y_continuous(limits = c(-1,1)) +
  scale_alpha_binned(breaks = c(0,0.05,0.1,1), range = c(0.8, 0.1)) +
  #facet_wrap(~(lwd100_lm_pval < 0.1))
  facet_wrap(~cmplx_strm + (lwd100_lm_pval < 0.1), ncol = 2)

```



# Intro 

Alongside flow and sediment, wood is fundamental to riverscape habitat dynamics. The 'natural wood regime' articulated by Wohl et al. (2019) describes recruitment, transport, and storage processes, each with the potential to vary in magnitude, duration, frequency, timing, and rate of change. This paradigm recognizes historical and ongoing simplification of the interactions among trees, rocks, and water in stream networks, and it describes the consequent fluvial habitat degradation, particularly in long-altered, temperate, forested watersheds. Indeed, this degradation has prompted widespread reintroduction of logs and 'coarse woody debris' in the western United States in recent decades, typically intended to benefit aquatic organisms via increased habitat diversity (Ockelford et al. 2024). 

Standardizing and systematizing the practice of such interventions, in conjunction with riparian and upland land management practices, and in the context of existing instream flow rules, would constitute the basis of 'target wood regimes' formulated to reverse impairments and meet other ecosystem service goals (Wohl et al. 2019). Yet practical management guidelines are still an area of active research, in part due to the logistical challenges of repeatedly and consistently counting wood and measuring its effects (e.g., Hassan 2022, Martens & Devine 2022, Scott 2024, Ruiz-Villanueva et al. 2024).

Foundational studies have suggested [key] thresholds...but constrained by...

surveying multiple locations once, inferring via space-for-time

or surveying single locations repeatedly, inferring via spatial extrapolation


  - Bilby & Ward 1989
    - relationship to channel size
  - Bilby & Ward 1991
    - .1 x 2m at 70 sites, varied length 100m - 1.5km
    - count density ~ channel size + forest_harvest (stand age) type
    - Fig 1 log10(n/m^2) ~ log10(width_m); note odd axis scaling
    - binned width at <7, 7-10, >10
    - for frequency and volume responses, saw less separation OG to CC/SG at the smaller sites <5-7m
    - could examine pool type obs relative to plunge/scour/backwater/dammed results

  - Collins et al. 2002
    - Nisq vs Sno & Stilly and vs archival
    
  - Hassan et al. 2005
    - Table 1 - survey of 20 studies diam & length values of 'large'
    - leads to table 2, categorical S-M-L based on ratios of piece length to channel width and piece diameter to depth...and phrasing of 'relative' wood and channel sizes
    - distinguishing 'headwater' processes by degree of hillslope coupling (decreasing with larger DA and greater bnkw) and lateral constraint as key determinant of dynamics (recruitment, transport, storage); higher-order channels presumably still subject to riparian and hillslope effects _but_ also influence of upstream network;
      - recruit: nice summary of mass wasting & avalanches for recruitment vs/as-well-as wind, bank erosion
      - storage: mostly about difficulty of measuring
      - output [transport plus 'attrition']: in headwaters, movement at highest flows only (esp largest pieces) supposing very episodic dyn
    - Fig2 (!!) Not have seen this previously is *highly congruent* with 'explorer_lwd' figures!! including 5m inflection noted in text but without the caveats of compiling across studies with varied protocol
      - testable: *"This has important implications for temporal and spatial variability of wood abundance in small streams, indicating that recruitment processes (and rates) from the adjacent hillslopes determine the spatial distribution and abundance of wood, while the time since the last debris flow explains the variance."*

  - Fox & Bolton 2007
    - ref conditions from 150 sites

However, few studies have described the dynamics of instream wood throughout the drainage networks of multiple streams over more than a decade. Here we quantify patterns of interannual wood variation between 2007 and 2024 at *NNN* consistently surveyed reaches within *NNN* small independent basins in western Washington, USA.

These data were collected as part of the Intensively Monitored Watersheds (IMW) program, a long-term, multi-location, collaborative evaluation of the population-level effects of habitat rehabilitation practices for Pacific salmon recovery (Bilby et al. 2005; Bennett et al. 2016). Physical and biological data are collected throughout several neighboring stream networks within each of the IMW 'complexes', enabling watershed-scale comparisons of the factors that may affect and limit salmonids in freshwater (Roni 2005; Bilby et al. 2023). Current best practice in stream rehabilitation seeks to identify 'limiting factors' and tailor 'process-based' interventions to ameliorate them. The IMW stream habitat observations extend and enrich our knowledge of how such processes presently operate in small, forested basins of the Pacific Northwest.

This paper examines spatial variation in the temporal variation in large wood density, asking how measures of change in time relate to network position and topographic attributes. 




  - Lininger & Hilton 2022
    - redwood long term
  - Martens & Devine 2022
    - single visit from 74 site/reaches western Olympics, focus on pool formation relative to wood piece size

  - Wohl et al 2019
    - Table 1 is nice summary of concepts & assumptions: recruitment/transport/storage relative to mag/freq/dur/timing/roc; other main aspect is the description of 'process-domains'
    - "However, until more data are available to accurately parameterize mechanistic, multiscale models of
wood regimes across regions (Scott and Wohl 2018), characterizing wood regimes over broad spatial scales will remain difficult"
    - Re: managing for target wood regimes: "documented effects of wood mobility suggest the importance of managing for dynamic rather than static wood loads within river corridors. Managing for wood dynamics is challenging because it requires identifying and managing for processes of wood recruitment and transport, which commonly involve wider and longer portions of a river network than the limited channel segments that are typically the focus of management (e.g., Boyer et al. 2003)."
  

  - Ockelford et al 2024 - working with wood in western US
  - Scott 2024 - jams in KingCo
    - jam measures signif but incompletely pred habitat morphological effects
  - Ruiz-Villanueva et al. 2024 https://onlinelibrary.wiley.com/doi/abs/10.1002/esp.5765


# Methods

## Data collection

## Analysis

- Reduced to sites with complete or nearly complete series (BIB drops above Symington?)
- George: what about redoing counts/densities better stratified by piece length and diameter

- ACF, AR1 as well as or instead of CV?
- KPSS
- corrr::correlate(method = "kendall") |> corrr::shave() |> corrr::rplot(print_cor = T) + scale_x_discrete(guide = guide_axis(n.dodge = 2))

# Results

- by response measure?


# Discussion

- Legally binding 'instream wood' requirements akin to stipulated flows at gaged control points?


  - McHenry et al. 1998
    - single repeat/contrast 82 vs 93 for 28 100m reaches, differentiating stable counts from decreased volumes due to OG loss
    - potentially useful contrast 


# Cited

Peterson E. E., Dumelle, M., Pearse A., Teleki D., and Ver Hoef, J. M. (2024). SSNbler: Assemble SSN objects in R. R package version 0.1.0
