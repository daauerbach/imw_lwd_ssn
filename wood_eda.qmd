---
title: "Exploration of W WA IMW wood count data"
author: "dan.auerbach@dfw.wa.gov"
date: "`r Sys.Date()`"
format:
  html:
    embed-resources: true
    theme: yeti 
    code-fold: true
    toc: true
    toc-location: left
    grid:
      sidebar-width: 180px
      body-width: 1100px
      margin-width: 20px
---



```{r setup}
library("tidyverse", quietly = T)
library("sf")
library("patchwork")
library("gt")
theme_set(theme_minimal()) 

dir_data_common <- "~/T/DFW-Team WDFW Watershed Synthesis - data_common"
epsg <- 2927 #WA state standard; NAD83(HARN)/ft

## uncomment to rebuild
# load("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/imw_hab_250307.RData")
# 
# wood_sy <- hab$lwd_site_year |> 
#   select(strm, site, year, up_down_lgth, bnk_wdth_mean, lgth_wdth, starts_with("d")) |> 
#   pivot_longer(cols = starts_with("d"), names_to = "dl", values_to = "n") 
# 
# #q75 separates m/l
# wood_classes <- wood_sy |>
#   summarise(
#     across(n, list(
#       q50 = ~median(., na.rm = T),
#       q75 = ~quantile(., p = 0.75, na.rm = T)
#       )), 
#     .by = c(dl)
#     ) |> 
#   arrange(desc(n_q75)) |> 
#   mutate(wood_class = rep(c("S","M","L"), each = 4) |> factor(levels = c("S","M","L"))) |> 
#   select(dl, wood_class)
# 
# #join and aggregrate by S/M/L classes
# wood_sy_sml <- wood_sy |> 
#   left_join(wood_classes, by = "dl") |>
#   summarise(
#     across(c(up_down_lgth, bnk_wdth_mean, lgth_wdth), ~.[1]),
#     across(n, sum),
#     .by = c(strm, site, year, wood_class)
#   )
# 
# #catchment polys nonspatially subset but COMIDs in streamcat
# sf_nhdp_wa <- readRDS("~/T/DFW-Team WDFW Watershed Synthesis - flow_trees_heat/sf_nhdp_wa.rds")
# #subset cat polys, to get comids can also use nhdplusTools::discover_nhdplus_id(sf_site_meta[1,])
# sf_site_nhdp <- sf_nhdp_wa[sf_site_meta,] |> select(-state)
# rm(sf_nhdp_wa)
# 
# site_comid <- st_join(sf_site_meta, sf_site_nhdp) |>
#   as_tibble() |> select(strm, site, comid) 
# #site_comid |> count(comid)
# 
# #reduce to water years 2000 (missing 1999 Oct-Dec) and 2023 (missing 2023 Jan-Sep)
# #takes a few but not terrible
# nwm <- expand_grid(y = 2000:2022, m = 1:12) |> 
#   mutate(wy = if_else(m > 9, y+1, y)) |>
#   filter(between(wy, 2001, 2022)) |> 
#   mutate(
#     nwm = map2(y, m,
#       ~readRDS(paste0("~/T/DFW-Team WDFW Watershed Synthesis - data_common/nwm_retro/v3_0/nwm_wa_",.x,"_",str_pad(.y,2,pad = "0"),".rds"))[,unique(site_comid$comid)]
#       )
#   ) |> 
#   unnest(nwm) |> 
#   mutate(d = seq_along(m), .by = c(y,m)) |> 
#   pivot_longer(cols = -c(y,m,wy,d), names_to = "comid", values_to = "cfs")

load("imw_wood_nwm.RData")

#NHDplusHR flowlines with DA, slope, elev etc from SSNbler prep
ssn <- readRDS("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/imw_lwd_ssn/ssns_list.rds")

sf_edges <- map_df(
  ssn,
  ~left_join(
    .x$edges |> select(NHDPlusID, dasqkm_tot, elev_min, slope, upDist)
    ,
    as_tibble(.x$obs) |> select(site, NHDPlusID)
    ,
    by = "NHDPlusID"
    ) |> 
    mutate(
      cmplx_strm = .x$obs$cmplx_strm[1],
      strm = .x$obs$strm[1]
    )
)

#sf_edges |> split(~strm) |> map(~ggplot(.x) + geom_sf(aes(color = strm)) + scale_color_manual(values = pal_strm)) |> wrap_plots()

```

demonstrating restratification by 75th quantile of count values per class, associating d10_l30 (skinny but long) with d20_l30 and the 2 shorter d30 classes
```{r f_supp_wood_classes}
{
#boxes by stream
wood_sy |> ggplot() + scale_fill_manual(values = pal_strm, aesthetics = c("color","fill")) +
  geom_boxplot(aes(dl, n, fill = strm, color = strm), linewidth = 0.3, alpha = 0.5, outlier.size = 0.5) +
  labs(x = NULL, title = "Sample distributions of site-year LWD counts by diameter and length class") +
    theme(legend.position = "top")
}+{
#boxes no stratification by stream
wood_sy |> ggplot() + 
  geom_boxplot(aes(dl, n), linewidth = 0.5, color = "grey30", outlier.size = 0.5) +
    geom_text(data = summarise(wood_sy, n_q75 = quantile(n, p = 0.75, na.rm = T), .by = dl),
              aes(dl, label = n_q75), y = 200) + #label = paste0("q75: ", n_q75)
  labs(x = "size class", subtitle = "75th quantile values in black")
}+ 
  plot_layout(ncol = 1)

```

demonstrating reln of areal-density with bankfull (i.e., no outside datasets)
[these plots are somewhat duplicative with below versions against DA rather than BFW, but keeping here for now]
the survey protocol increases longitudinal transect spacing with greater bankfull width, such that a larger area is observed 
counts normalized by surveyed area show consistent decline with site-reach bankfull width, especially for smallest size class
if density were constant with bankwidth, raw counts would increase with bankfull, as larger observed area meant more wood encountered
```{r f_count_bnk_wdth}
#may not want 3rd order poly as fit line and R2?
wood_sy_sml |> 
  mutate(
    n_m2 = n / lgth_wdth,
    n_1000m2 = 1000 * (n / lgth_wdth)
    ) |> 
  ggplot(aes(bnk_wdth_mean, n_m2, color = strm)) +
#  ggplot(aes(bnk_wdth_mean, n_100m2, color = strm)) +
  scale_fill_manual(values = pal_strm, aesthetics = c("color","fill")) +
  geom_point(size = 0.3, alpha = 0.6, show.legend = F) +
  #ggpmisc::stat_poly_line(color = "blue") +
  ggpmisc::stat_poly_line(formula = y ~ poly(x, degree = 3, raw = T), color = "red", se = F) +
  #ggpmisc::stat_poly_eq(ggpmisc::use_label(c("adj.R2", "p")), color = "blue") +
  ggpmisc::stat_poly_eq(ggpmisc::use_label(c("adj.R2")), formula = y ~ poly(x, degree = 3, raw = T), color = "red", ) +
  #facet_wrap(~strm+lwd_class, labeller = label_wrap_gen(multi_line = F))
  facet_wrap(wood_class~strm, labeller = label_wrap_gen(multi_line = F), nrow = 3, scale = "free_y")

```
sd of areal density also decays with bankfull but as expected for strong pos corr sd~mean
```{r f_count_sd}
wood_sy_sml |> 
  mutate(
    n_m2 = n / lgth_wdth,
    n_1000m2 = 1000 * (n / lgth_wdth)
    ) |> 
  summarise(
    across(c(bnk_wdth_mean, n, n_m2), list(mean = ~mean(., na.rm=T))) ##grand means per site across years
    ,
    across(c(n, n_m2), list(sd = ~sd(., na.rm = T))), .by = c(strm, site, wood_class)
    ) |> 
# #  ggplot(aes(bnk_wdth_mean_mean, n_sd, color = strm)) +
#   ggplot(aes(bnk_wdth_mean_mean, n_m2_sd, color = strm)) +
#   scale_fill_manual(values = pal_strm, aesthetics = c("color","fill")) +
#   geom_point(size = 0.3, alpha = 0.6, show.legend = F) +
#   facet_wrap(wood_class~strm, labeller = label_wrap_gen(multi_line = F), nrow = 3, scale = "free_y")
### as expected given...
  ggplot(aes(n_m2_mean, n_m2_sd, size = bnk_wdth_mean_mean, color = strm)) + 
  scale_fill_manual(values = pal_strm, aesthetics = c("color","fill")) + 
  geom_point(alpha = 0.4) +
  facet_wrap(~wood_class, labeller = label_wrap_gen(multi_line = F), nrow = 3, scale = "free_y")
```

## wood_sy_sml initial hiearchical model testing {.content-hidden when-format="html"}

create a year-complete object of counts by class, q99, and dasqkm/slope/elev

```{r wood_sy_sml_nwm, include=FALSE, eval=FALSE}
# #recall that 'wood_sy' backed up to hab, prior to site exclusion by n-years-obs
# #could constrain further by number of years obs
# #semi-join on site_meta still includes several sites with <10 years
# wood_sy_sml |>
#   #anti_join(site_meta, by = c("strm", "site")) |>
#   semi_join(site_meta, by = c("strm", "site")) |> 
#   distinct(strm, site, year) |> 
#   summarise(
#     n = n(),
#     .by = c(strm, site)
#     ) |>
#   arrange(n) |> print(n = 20)

#complete() version to make missing explicit
#this creates many per-year repeats of the fixed site attributes da, slope, elev
wood_sy_sml_nwm <- wood_sy_sml |> 
  inner_join(
    site_meta |> select(cmplx_abrv, cmplx_strm, site),
    by = c("site")
  ) |> 
  filter(
    !(site %in% c(
      "STA020", #too few years for comparison? but could/should also apply that to ~15 other sites?
      "DEW243", "DEW067", "AND002", "GER004", #based on inspection driven by acf looks that showed larger missing gaps
      "SEA064" #not in sf_edges
    ))
  ) |> 
  pivot_wider(names_from = wood_class, values_from = n, names_prefix = "n_") |> 
  mutate(
    across(
      starts_with("n"),
      list(
        m2 = ~. / lgth_wdth,
        `1000m2` = ~1000*(. / lgth_wdth)
      )
    ),
    .by = site
  ) |> 
  group_by(cmplx_abrv, cmplx_strm, strm, site) |> 
  complete(year = 2007:2024) |> 
  ungroup() |>
  left_join(site_comid, by = c("strm","site")) |> 
  left_join(
    nwm |> 
      summarise(
        across(cfs, list(
          #q90 = ~quantile(.,p=c(0.9)),
          #q95 = ~quantile(.,p=c(0.95)) ,
          q99 = ~quantile(.,p=c(0.99)) #,
          #max = ~max(.)
        )),
        .by = c(comid, wy)
      )
    ,
    by = c("comid", "year" = "wy")    
  ) |> 
  left_join(as_tibble(sf_edges) |> select(site, dasqkm_tot:upDist), by = "site")

# #various NAs for padded years
# wood_sy_sml_nwm |> summary() 

```

```{r f_years_obs_point, include=FALSE, eval=FALSE}
wood_sy_sml_nwm |> 
  drop_na(n_L) |> 
  ggplot(aes(year, site, color = cmplx_strm)) + 
  geom_point(size =0.5, show.legend = F) + 
  scale_x_continuous(breaks = seq(2007, 2024, by = 2)) +
  scale_fill_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
  facet_wrap(~cmplx_strm, ncol = 1, scales = "free_y") + 
  labs(x = NULL, y = NULL) + 
  theme(axis.text.y = element_text(size = 4))

#ggsave("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/fig/f_years_obs_point.png", height = 14, width = 10, bg = "white", dpi = 100)
```

```{r wood_sy_sml_nwm_musdcv, include=FALSE, eval=FALSE}
wood_sy_sml_nwm_musdcv <- wood_sy_sml_nwm |> 
  summarise(
    across(
      ends_with("m2"), 
      list(
        mu = ~mean(., na.rm = T),
        sd = ~sd(., na.rm = T)
      )),
    .by = c(cmplx_abrv, cmplx_strm, strm, site, 
            #comid, 
            dasqkm_tot, elev_min, slope)
  ) |> 
  mutate(
    n_S_1000m2_cv = n_S_1000m2_sd / n_S_1000m2_mu,
    n_M_1000m2_cv = n_M_1000m2_sd / n_M_1000m2_mu,
    n_L_1000m2_cv = n_L_1000m2_sd / n_L_1000m2_mu,
    across(
      c(ends_with("sd"), ends_with("cv")), 
      list(log = ~log(.)))
  ) |> 
  arrange(strm)


# wood_sy_sml_nwm_musdcv |> 
#   select(strm, site, dasqkm_tot, ends_with("sd_log")) |>
#   pivot_longer(ends_with("sd_log")) |>
#   ggplot(aes(dasqkm_tot, value, color = strm)) +
#   geom_point(show.legend = F) +
#   ggpmisc::stat_poly_line(color = "blue") +
#   ggpmisc::stat_poly_eq(ggpmisc::use_label(c("adj.R2", "p")), color = "blue") +
#   scale_fill_manual(values = pal_strm, aesthetics = c("color","fill")) +
#   facet_wrap(~name + strm, nrow = 3, scales = "free")

```


expected clear pos corr
```{r f_sd_vs_mu, include=FALSE, eval=FALSE}
wood_sy_sml_nwm_musdcv |> 
  select(cmplx_abrv, cmplx_strm, strm, site, ends_with("1000m2_mu"), ends_with("1000m2_sd")) |> 
  pivot_longer(cols = starts_with("n_")) |> 
  mutate(
    wood_class = str_sub(name,3,3),
    var = str_sub(name,-2,-1), #var = str_sub(name,-9,-1),
    name = NULL
    ) |> 
  pivot_wider(names_from = var, values_from = value) |> 
  ggplot(aes(mu, sd, color = cmplx_strm)) +
  geom_point(size = 0.7, show.legend = F) +
  geom_smooth(show.legend = F) +
  scale_color_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
  facet_wrap( ~wood_class + cmplx_strm, nrow = 3, scales = "free")
ggsave("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/fig/f_wood_sy_sml_nwm_sd_vs_mu.png", width = 11, height = 9, dpi = 150, bg = "white")

```
more varied but still apparent negative log-linear corr
```{r mu_vs_da, include=FALSE, eval=FALSE}
wood_sy_sml_nwm_musdcv |> 
  select(cmplx_abrv, cmplx_strm, strm, site,
         dasqkm_tot, elev_min, slope,
         ends_with("1000m2_mu"), ends_with("1000m2_sd")) |> 
  pivot_longer(cols = starts_with("n_")) |> 
  mutate(
    wood_class = str_sub(name,3,3),
    var = str_sub(name,-2,-1), #var = str_sub(name,-9,-1),
    name = NULL
    ) |> 
  pivot_wider(names_from = var, values_from = value) |> 
  ggplot(aes(dasqkm_tot, mu, color = cmplx_strm)) +
  geom_point(size = 0.7, show.legend = F) +
  geom_smooth(show.legend = F) +
  scale_x_log10() +
  scale_color_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
  facet_wrap( ~wood_class + cmplx_strm, nrow = 3, scales = "free")

ggsave("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/fig/f_wood_sy_sml_nwm_mu_vs_da.png", width = 11, height = 9, dpi = 150, bg = "white")

```
nearly identical as expected to mean-vs-da
```{r sd_vs_da, include=FALSE, eval=FALSE}
wood_sy_sml_nwm_musdcv |> 
  select(cmplx_abrv, cmplx_strm, strm, site,
         dasqkm_tot, elev_min, slope,
         ends_with("1000m2_mu"), ends_with("1000m2_sd")) |> 
  pivot_longer(cols = starts_with("n_")) |> 
  mutate(
    wood_class = str_sub(name,3,3),
    var = str_sub(name,-2,-1), #var = str_sub(name,-9,-1),
    name = NULL
    ) |> 
  pivot_wider(names_from = var, values_from = value) |> 
  ggplot(aes(dasqkm_tot, sd, color = cmplx_strm)) +
  geom_point(size = 0.7, show.legend = F) +
  geom_smooth(show.legend = F) +
  scale_x_log10() +
  scale_color_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
  facet_wrap( ~wood_class + cmplx_strm, nrow = 3, scales = "free")

ggsave("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/fig/f_wood_sy_sml_nwm_sd_vs_da.png", width = 11, height = 9, dpi = 150, bg = "white")

```
much less clear univariate pattern
```{r cv_vs_da, include=FALSE, eval=FALSE}
wood_sy_sml_nwm_musdcv |> 
  select(cmplx_abrv, cmplx_strm, strm, site,
         dasqkm_tot, elev_min, slope,
         ends_with("cv")
         ) |> #summary() #looks like *1000 controls to only a few outlier inflated by small mu
  pivot_longer(cols = ends_with("cv")) |> 
  mutate(
    wood_class = str_sub(name,3,3),
    var = str_sub(name,-2,-1), #var = str_sub(name,-9,-1),
    name = NULL
    ) |> 
  pivot_wider(names_from = var, values_from = value) |> 
  ggplot(aes(dasqkm_tot, cv, color = cmplx_strm)) +
  geom_point(size = 0.7, show.legend = F) +
  geom_smooth(show.legend = F) +
  scale_x_log10() +
  scale_color_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
  facet_wrap( ~wood_class + cmplx_strm, nrow = 3, scales = "free")

ggsave("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/fig/f_wood_sy_sml_nwm_cv_vs_da.png", width = 11, height = 9, dpi = 150, bg = "white")

```


```{r test_brms_hier_SD, include=FALSE, eval=FALSE}
#trying from: https://chatgpt.com/share/6802ad1a-07b0-8003-b161-e3ea9131a407
#modified to try starting with linear fixed effects and streams within complexes as nested random effects

library(brms)

# Optional: set informative or weakly informative priors
priors <- c(
  prior(normal(0, 1), class = "b"),                    # for fixed effects
  prior(student_t(3, 0, 2.5), class = "Intercept"),    # intercept
  prior(cauchy(0, 1), class = "sd")                    # for random effects
)

fit <- brm(
  formula = n_L_m2_sd_log ~ 
    #s(dasqkm_tot) + s(slope) + s(elev_min) + 
    dasqkm_tot + slope + elev_min + 
    (1 | cmplx_abrv/strm)
  ,   # nested random effects
  data = wood_sy_sml_nwm_sd |> #summary()
    filter(is.finite(n_L_m2_sd_log)) |> #BIB010 & BIB012
    drop_na(dasqkm_tot) #SEA064
  ,
  family = gaussian(),
  prior = priors,
  chains = 2,
  cores = 2,
  iter = 1000,
  control = list(adapt_delta = 0.95),
  seed = 123
)

summary(fit)             # parameter estimates
plot(fit)                # smooths and residuals
pp_check(fit)            # posterior predictive checks
loo(fit)                 # leave-one-out CV
conditional_effects(fit) # plot smooths with uncertainty
ranef(fit)

#trying to think through interpretation of backtransformed
-5.71 + -0.04*20 |> exp()
#for each additional sqkm DA, the log of sd of density decreases 0.04...dependent on cmplx/strm/slope/elev?
plot(1:75, -5.71 + -0.04*1:75, type = "l")
plot(1:75, exp(-5.71 + -0.04*1:75), type = "l")

nd <-wood_sy_sml_nwm_sd |> #summary()
  distinct(cmplx_abrv, strm) |> 
  mutate(slope = 0.05, elev_min = 125) |> 
  expand_grid(dasqkm_tot = seq(1,60, by = 5))
nd <- as_tibble(cbind(nd,  predict(fit, nd)))
  

wood_sy_sml_nwm_sd |> 
  #ggplot(aes(dasqkm_tot, n_L_m2_sd_log)) + geom_point(size = 0.7)
  ggplot(aes(dasqkm_tot, n_L_m2_sd)) + geom_point(size = 0.7) + 
  geom_hline(yintercept = exp(-5.71 + -0.04*20)) +
  geom_line(
    data = tibble(dasqkm_tot = 1:75, n_L_m2_sd = exp(-5.71 + -0.04*dasqkm_tot)), color = "orange"
  ) +
  geom_line(
    data = nd, aes(y = exp(Estimate), color = strm)
  ) +
  scale_fill_manual(values = pal_strm, aesthetics = c("color","fill"))

```

```{r test_brms_hier_negbin_ar, include=FALSE, eval=FALSE}

library(brms)

#sampling without specified priors but would prefer to specify
#need to check what/how brms is doing with NAs being excluded relative to ar()
fit <- brm(
  n_L ~ dasqkm_tot + slope + elev_min + (1 | cmplx_abrv/strm/site) +
    ar(time = year, gr = site, p = 1) + # AR(1) process within each site
    offset(log(lgth_wdth)), # correct for varying survey area
  data = d,
  family = negbinomial(),
  chains = 2,
  cores = 2,
  iter = 1000,
  control = list(adapt_delta = 0.95),
  seed = 123
)

#performance::check_model(fit)

summary(fit)             # parameter estimates
plot(fit)                # smooths and residuals
plot(conditional_effects(fit), ask = F) |> 
  wrap_plots()
#pp_check(fit)            # posterior predictive checks
loo(fit)                 # leave-one-out CV
ranef(fit)


fit_pp <- as_tibble(t(posterior_predict(fit)))  # cmplx_abrv:strm:site-years x draws
fit_pp$site <- fit$data$site  #fit$data$`cmplx_abrv:strm:site` 
fit_pp$cmplx_strm <- fit$data$`cmplx_abrv:strm`
fit_pp |> count(site) |> arrange(n) #not year-complete as NAs have been dropped in fit

#observed SD + distrib of posterior SDs
#cool but unclear that need to 'predict' with uncertainty the volatility per-site
#as much as examine conditional effects across streams/complexes?
d_site_sd <- d |> 
  summarise(
    across(n_L, list(obs_sd = ~sd(., na.rm = T))),
    .by = c(cmplx_strm, site)
  ) |> 
  mutate(site = fct_reorder(site, n_L_obs_sd, identity), .by = cmplx_strm)
        
fit_pp_sd <- fit_pp |>
  summarise(across(V1:V1000, list(sd = ~sd(.))), .by = c(cmplx_strm, site)) |> 
  pivot_longer(cols = starts_with("V")) |> 
  mutate(site = factor(site, levels = levels(d_site_sd$site)))

ggplot(mapping = aes(y = site, color = cmplx_strm, fill = cmplx_strm)) +
  # geom_boxplot(
  #   data = fit_pp_sd,
  #   mapping = aes(x = value), outlier.alpha = 0.5, outlier.size = 0.6, show.legend = F
  # ) +
  ggridges::geom_density_ridges(
    data = fit_pp_sd,
    mapping = aes(x = value), alpha = 0.5,
    show.legend = F
  ) +
  geom_point(
    data = d_site_sd,
    aes(x = n_L_obs_sd), shape = 3, size = 1.2, color = "grey20", show.legend = F
  ) +
  scale_fill_manual(values = pal_cmplx_strm, aesthetics = c("color","fill")) +
  facet_wrap(~cmplx_strm, scales = "free") +
  labs(
    title = "Posterior predicted distributions of per-site SD of n_L counts", x = NULL, y = NULL,
    subtitle = fit$formula
    )


ce <- conditional_effects(
  fit,
  effects = "dasqkm_tot",
#these run but are not actually adding anything to the data.frame...
  #re_formula = NULL, 
  #re_formula = '~ (1 | cmplx_abrv/strm)',
  conditions = make_conditions(fit, var = "slope"),
  rug = T, prob = c(0.95)
  )
ce
#this 'works' to overplot, but it seems like either a better option coded somewhere
#or go back to explicit predict(newdata) with expand_grid known defined levels...
ce$dasqkm_tot |> ggplot() + geom_line(aes(dasqkm_tot, estimate__, color = cond__))

#this shows how the complexes affect the intercept
coef(fit, robust = T)$cmplx_abrv
#and similarly the strms...
coef(fit, robust = T)$`cmplx_abrv:strm`
#but not the response in response units...


#'If you suspect that volatility differs structurally across sites, streams, or complexes, and you include random slopes or intercepts, you can extract their posterior variances. This tells you how much residual interannual variation is left at each level (site, stream, complex) — and you can see if it’s large enough to justify modeling.'
as.data.frame(VarCorr(fit))
#seems to be same info as in summary(fit) but without diagnostics
#unclear what to do with this


#attempting random effects for slopes as well as intercept
#possibly a bad idea
fit2 <- brm(
#this is completely removing physio vars as fixed
#and pretty unclear to me what it is generating
  #n_L ~ (1 + dasqkm_tot + slope + elev_min | cmplx_abrv/strm/site) +
#should be?
  n_L ~ dasqkm_tot + slope + elev_min + #fixed
    (1 + dasqkm_tot + slope + elev_min | cmplx_abrv/strm/site) + #random slopes and intercepts
    ar(time = year, gr = site, p = 1) + # AR(1) process within each site
    offset(log(lgth_wdth)), # correct for varying survey area
  data = d,
  family = negbinomial(),
  chains = 2,
  cores = 2,
  iter = 1000,
  control = list(adapt_delta = 0.95),
  seed = 123
)

# #all fixed
# ## this is easily the worst thing tried out the gate and the coef estimate values make little sense at least initially
# fit3 <- brm(
#   n_L ~ dasqkm_tot + slope + elev_min + cmplx_abrv + strm + 
#     ar(time = year, gr = site, p = 1) + # AR(1) process within each site
#     offset(log(lgth_wdth)), # correct for varying survey area
#   data = d,
#   family = negbinomial(),
#   chains = 2,
#   cores = 2,
#   iter = 1000,
#   control = list(adapt_delta = 0.95),
#   seed = 123
# )
# #try? seems wrong
#   n_L ~ dasqkm_tot*cmplx_abr + slope*cmplx_abrv + elev_min*cmplx_abrv +
#         dasqkm_tot*strm + slope*strm + elev_min*strm +



#per cmplx, s(year)
fit_hc <- brm(
  n_L ~ dasqkm_tot + slope + elev_min + 
    s(year) +
    (1 | strm/site) +
    #ar(time = year, gr = site, p = 1) + # AR(1) process within each site
    offset(log(lgth_wdth)), # correct for varying survey area
  data = d |> filter(cmplx_abrv == "HC"),
  family = negbinomial(),
  chains = 2,
  cores = 2,
  iter = 1000,
  control = list(adapt_delta = 0.95),
  seed = 123
)

fit_hc |> 
  conditional_effects(
  effects = "dasqkm_tot",
  re_formula = NULL, 
  conditions = make_conditions(fit_hc, var = "slope"),
  rug = T, prob = c(0.95)
  )

```

```{r test_glmernb, include=FALSE, eval=FALSE}
#https://stats.stackexchange.com/questions/198367/incorporating-auto-correlation-structure-into-a-negative-binomial-generalized-ad
#https://stats.stackexchange.com/questions/311556/help-interpreting-count-data-glmm-using-lme4-glmer-and-glmer-nb-negative-binom

#not sure these are temp autocorr enough to worry about?
d |> 
  nest(.by = c(cmplx_strm, site)) |> 
  mutate(
    acf1 = map_dbl(data, ~acf(.x$n_L, 1, plot = F, na.action = na.pass)$acf[2])
    ) |> 
  ggplot() + 
  geom_boxplot(aes(acf1, cmplx_strm, color = cmplx_strm), position = "dodge", show.legend = F)

#just space, treating per-year counts as independent, ignoring 'longitudinal' character
f1 <- lme4::glmer.nb(
  n_L ~ log10(dasqkm_tot) + slope + log10(elev_min) + 
    (1 | cmplx_abrv/strm/site) +
    offset(log(lgth_wdth)), # correct for varying survey area
  data = d, verbose = TRUE
)

#adding year as fixed effect
#this runs and year is 'signif', but not at all clear this is a sensible approach with 17-18 years (either as 1:17 or factor())
f2 <- lme4::glmer.nb(
  n_L ~ log10(dasqkm_tot) + slope + log10(elev_min) + 
    year + 
    (1 | cmplx_abrv/strm/site) +
    offset(log(lgth_wdth)), # correct for varying survey area
  #data = d |> mutate(year = year - 2006) #treating time as linear fixed effect
  data = d |> mutate(year = factor(year)) #treating year as categorical/distinct f.e.
  , 
  verbose = TRUE
)


summary(f1)
summary(f2)

performance::check_model(f1)
performance::check_model(f2)

f1_r <- DHARMa::simulateResiduals(fittedModel = f1, plot = T)
f2_r <- DHARMa::simulateResiduals(fittedModel = f2, plot = T)


#fit per single complex, sites nested in streams
#would be nice to fit s(year) but that's brms
f_hc <- lme4::glmer.nb(
  n_L ~ log10(dasqkm_tot) + slope + log10(elev_min) + 
    year + 
    (1 | strm/site) +
    offset(log(lgth_wdth)), # correct for varying survey area
  data = d |> mutate(year = year - 2006) |> 
    filter(cmplx_abrv == "HC")
  #data = d |> mutate(year = factor(year)) #treating year as categorical/distinct f.e.
  , 
  verbose = TRUE
)
f_lc <- lme4::glmer.nb(
  n_L ~ log10(dasqkm_tot) + slope + log10(elev_min) + 
    year + 
    (1 | strm/site) +
    offset(log(lgth_wdth)), 
  data = d |> mutate(year = year - 2006) |> 
    filter(cmplx_abrv == "LC")
  , 
  verbose = TRUE
)
f_st <- lme4::glmer.nb(
  n_L ~ log10(dasqkm_tot) + slope + log10(elev_min) + 
    year + 
    (1 | strm/site) +
    offset(log(lgth_wdth)), 
  data = d |> mutate(year = year - 2006) |> 
    filter(cmplx_abrv == "ST")
  , 
  verbose = TRUE
)

summary(f_hc) #all about 'year'
summary(f_lc) #no 'year, all about space
summary(f_st) #yet again different, both space and year

#back to SD, family is gaussian by default
f_sd <- lme4::lmer(
  formula = n_L_m2_sd_log ~ 
    log10(dasqkm_tot) + slope + log10(elev_min) + 
    (1 | cmplx_abrv/strm)
  ,
  data = wood_sy_sml_nwm_sd |> #summary()
    filter(is.finite(n_L_m2_sd_log)) |> #BIB010 & BIB012
    drop_na(dasqkm_tot) #SEA064
  , verbose = T
)
library(lmerTest)
summary(f_sd)
anova(f_sd)
performance::check_model(f_sd)
#give pvals for fixed though apparently these are not desirable
f_sd_nlme <- nlme::lme(
  n_L_m2_sd_log ~ log10(dasqkm_tot) + slope + log10(elev_min)
  ,
  random = ~ 1 | cmplx_abrv/strm
  ,
  data = wood_sy_sml_nwm_sd |> #summary()
    filter(is.finite(n_L_m2_sd_log)) |> #BIB010 & BIB012
    drop_na(dasqkm_tot) #SEA064
  ) 
f_sd_nlme
summary(f_sd_nlme) #anova(f_sd_nlme)

```

this is really probably mostly showing effect of mean ~ DA
```{r back_to_basics_sd, include=FALSE, eval=FALSE}
d_sd <- wood_sy_sml_nwm_sd |> #summary()
    filter(is.finite(n_L_m2_sd_log)) |> #BIB010 & BIB012
    drop_na(dasqkm_tot) #SEA064
#similar to initial tests fitting per-stream in wood_sy_sml_nwm_SD_lm
#but simplest 'pooled' approaches? 
#first physio only, ignoring streams
f_sd_lm <- lm(
  n_L_m2_sd_log ~ log10(dasqkm_tot) + slope + log10(elev_min),
  data = d_sd
)
#r2 ~0.27, not a great model but sees lots of DA effect
summary(f_sd_lm); anova(f_sd_lm)
performance::check_model(f_sd_lm) 

#next stream as fixed effect
f_sd_lm_strm <- lm(
  n_L_m2_sd_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + strm,
  data = d_sd
)
#better model? r2 ~0.43, still strong effect for DA, but also clearly for strm and signif est for elev
#still has trouble at hi/lo
#what is utility of having stream-specific coef estimates?
#maybe more the `anova` output indicating that 'strm' itself is more determinative than slope|elev
#but still seems most useful as demo of why this is not best option? 
summary(f_sd_lm_strm); anova(f_sd_lm_strm)
performance::check_model(f_sd_lm_strm) 
performance::r2(f_sd_lm_strm) 

#next stream (only) as random effect
f_sd_lmer_strm <- lme4::lmer(
  n_L_m2_sd_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + 
    (1 | strm)
  ,
  data = d_sd, verbose = T
)
#finds effects for DA and (modest) elev
summary(f_sd_lmer_strm); anova(f_sd_lmer_strm)
performance::check_model(f_sd_lmer_strm)
performance::r2(f_sd_lmer_strm) #apparently a dubious quantity

anova(f_sd_lmer_strm, f_sd_lm_strm)

library(brms)
#no stream effect, fixed or random; linear covars
f_sd_brm <- brm(
  n_L_m2_sd_log ~ log10(dasqkm_tot) + slope + log10(elev_min),
  data = d_sd,
  family = gaussian(),
#  prior = priors,
  chains = 2, cores = 2, iter = 1000, control = list(adapt_delta = 0.95), seed = 123
)
#fixed effect of stream
f_sd_brm_strm <- brm(
  n_L_m2_sd_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + strm,
  data = d_sd,
  family = gaussian(),
#  prior = priors,
  chains = 2, cores = 2, iter = 1000, control = list(adapt_delta = 0.95), seed = 123
)
#random effect of stream (allowing per-stream intercept of the mean log_sd)
f_sd_brm_strm_re <- brm(
  n_L_m2_sd_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + (1 | strm),
  data = d_sd,
  family = gaussian(),
#  prior = priors,
  chains = 2, cores = 2, iter = 1000, control = list(adapt_delta = 0.95), seed = 123
)

summary(f_sd_brm)
summary(f_sd_brm_strm)
summary(f_sd_brm_strm_re)

f_sd_brm <- add_criterion(f_sd_brm, "waic")
f_sd_brm_strm <- add_criterion(f_sd_brm_strm, "waic")
f_sd_brm_strm_re <- add_criterion(f_sd_brm_strm_re, "waic")

loo(f_sd_brm)
loo(f_sd_brm_strm)
loo_compare(f_sd_brm, f_sd_brm_strm, f_sd_brm_strm_re, criterion = 'waic')

pp_check(f_sd_brm)
pp_check(f_sd_brm_strm)
pp_check(f_sd_brm_strm_re)

map(
  list(f_sd_brm, f_sd_brm_strm, f_sd_brm_strm_re)
  ,
  ~conditional_effects(
    .x,
    effects = "dasqkm_tot",
    re_formula = NULL, 
    conditions = make_conditions(.x, var = "slope"), rug = T, prob = c(0.95)
  )
)

ce <- conditional_effects(
    f_sd_brm_strm_re,
    effects = "dasqkm_tot",
    re_formula = NULL, 
    #conditions = make_conditions(f_sd_brm_strm_re, var = "slope"), rug = T, prob = c(0.95)
    conditions = make_conditions(f_sd_brm_strm_re, var = "strm"), rug = T, prob = c(0.95)
  )
#maybe interesting?
ce$dasqkm_tot |> 
  ggplot(aes(dasqkm_tot, estimate__, color = strm, fill = strm)) +
  #geom_smooth()  + 
  geom_line() + geom_ribbon(aes(ymin = lower__, ymax = upper__), alpha = 0.4) + 
  scale_color_manual(values = pal_strm, aesthetics = c("color","fill"))


#do an sf prediction
```
should bring the log(cv) back up to earlier object declaration
```{r back_to_basics_cv, include=FALSE, eval=FALSE}
d_cv <- wood_sy_sml_nwm_sd |> 
  select(cmplx_abrv, cmplx_strm, strm, site,
         dasqkm_tot, elev_min, slope,
         ends_with("cv")
         ) |> 
  drop_na(n_L_1000m2_cv, dasqkm_tot) |>  #|> summary()
  mutate(
    across(ends_with("cv"), list(log = ~log(.)))
  )
  
#similar to initial tests fitting per-stream in wood_sy_sml_nwm_SD_lm
#but simplest 'pooled' approaches? 
#first physio only, ignoring streams
f_cv_lm <- lm(
  n_L_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min),
  data = d_cv
)
#r2 ~0.04!, not a great model! minor DA & elev
summary(f_cv_lm); anova(f_cv_lm)
performance::check_model(f_cv_lm) 

#next stream as fixed effect
f_cv_lm_strm <- lm(
  n_L_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + strm,
  data = d_cv
)
#not much better model
summary(f_cv_lm_strm); anova(f_cv_lm_strm)
performance::check_model(f_cv_lm_strm) 

#next stream (only) as random effect
f_cv_lmer_strm <- lme4::lmer(
  n_L_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + (1 | strm),
  data = d_cv, verbose = T
)
#maybe modest effects for elev and perhaps slope
summary(f_cv_lmer_strm); anova(f_cv_lmer_strm)
performance::check_model(f_cv_lmer_strm)
performance::r2(f_cv_lmer_strm) #apparently a dubious quantity
#no meaningful diffs
anova(f_cv_lmer_strm, f_cv_lm_strm, f_cv_lm)

#could/should test further for differences by wood class?
#simple for cv of "S" is not great but better overall model and finds DA and elev effects
f_cv_lm_S <- lm(n_S_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min), data = d_cv)
summary(f_cv_lm_S) 
#whereas cv M is terrible!
f_cv_lm_M <- lm(n_M_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min), data = d_cv)
summary(f_cv_lm_M) 

f_cv_lmer_strm_S <- lme4::lmer(
  n_S_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + (1 | strm),
  data = d_cv, verbose = T
)
summary(f_cv_lmer_strm_S)
anova(f_cv_lmer_strm_S, f_cv_lmer_strm)

library(brms)
#no stream effect, fixed or random; linear covars
f_cv_brm <- brm(
  n_L_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min),
  data = d_cv,
  family = gaussian(),
#  prior = priors,
  chains = 2, cores = 2, iter = 1000, control = list(adapt_delta = 0.95), seed = 123
)
#fixed effect of stream
f_cv_brm_strm <- brm(
  n_L_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + strm,
  data = d_cv,
  family = gaussian(),
#  prior = priors,
  chains = 2, cores = 2, iter = 1000, control = list(adapt_delta = 0.95), seed = 123
)
#random effect of stream (allowing per-stream intercept of the mean log_sd)
f_cv_brm_strm_re <- brm(
  n_L_1000m2_cv_log ~ log10(dasqkm_tot) + slope + log10(elev_min) + (1 | strm),
  data = d_cv,
  family = gaussian(),
#  prior = priors,
  chains = 2, cores = 2, iter = 1000, control = list(adapt_delta = 0.95), seed = 123
)

summary(f_cv_brm)
summary(f_cv_brm_strm)
summary(f_cv_brm_strm_re)

f_cv_brm <- add_criterion(f_cv_brm, "waic")
f_cv_brm_strm <- add_criterion(f_cv_brm_strm, "waic")
f_cv_brm_strm_re <- add_criterion(f_cv_brm_strm_re, "waic")

loo(f_cv_brm)
loo(f_cv_brm_strm)
loo_compare(f_cv_brm, f_cv_brm_strm, f_cv_brm_strm_re, criterion = 'waic')

pp_check(f_cv_brm)
pp_check(f_cv_brm_strm)
pp_check(f_cv_brm_strm_re)


ce <- conditional_effects(
    f_cv_brm_strm_re,
    effects = "slope",
    re_formula = NULL, 
    #conditions = make_conditions(f_cv_brm_strm_re, var = "slope"), rug = T, prob = c(0.95)
    conditions = make_conditions(f_cv_brm_strm_re, var = "strm"), rug = T, prob = c(0.95)
  )
#maybe interesting?
ce$slope |> 
  ggplot(aes(slope, estimate__, color = strm, fill = strm)) +
  #geom_smooth()  + 
  geom_line() + geom_ribbon(aes(ymin = lower__, ymax = upper__), alpha = 0.4) + 
  scale_color_manual(values = pal_strm, aesthetics = c("color","fill"))

```


[Original 'prelim' now seeming more like sd as proportional to mu, 
such that variation magnitude is not separable from overall mean woodiness...
but also have not thoroughly tested log(cv) of "S" and "M"]
Prelim finding: basic physiographic/network-position measures can account for much of the variation in the magnitude of interannual variation in 'large' wood, distinguishing the smaller 'ongoing churn' size pieces from the 'keystone' very large pieces; complemented with NWM peak flow correlations for S vs M/L

- Drop 'complex' as a nesting/hier layer
  - could fit separately by complex, nesting sites in streams,
  - or include as fixed covar still with 1|strm/site,
  - or ignore altogether still with 1|strm or 1|strm/site

- Time-summarized response if focus is really on simply on spatial pattern and predictors of condition & volatility? 
  - looks like reasonable fits for mu and log(sd) but with log(sd) arguably less a reflection of 'volatility'-perse than the scale of characteristic woodiness (bigger swings in SD reflect more wood to come and go, not as much fluvial geomorph process variation within network?)
  - cv of L or M do not look likely to be well fit with linear covars; cv of S maybe and perhaps smooth terms in brms approach
  - re-examine median abs diff vs mean abs diff

- Full time series response to parse variation as spatial vs temporal?
  - other hab measures series?
  
- spatial extension via RC VBET or DNR RShydro valley attrib?

Dataset:
  - response: longitudinal/time series of yearly 2007-2024 counts (by size class) with offset at sites (20-30) nested in streams (10) in complexes (3)
    - spatial (strong) and temporal (modest) autocorrelation
    - randomized sampling design but order of magnitude diff in sampling density as sites/stream_km and imperfectly uniform network coverage
  - predictors: 
    - atemporal physiographic/spatial stream network attributes - drainage/contributing area, site/reach slope (gradient)
    - time varying: year and/or regional hydroclimate fluctuations actually estimated via NWM3.0 high flow values
    - likely subject to similar spatiotemporal autocorrelation(s) as the response


sf map sd of arealdensity

```{r map_m2_sd, include=FALSE, eval=FALSE}
#quick and ugly
sf_site_meta |> 
  select(cmplx_abrv, strm, site) |> 
  inner_join(
    wood_sy_sml_nwm_musdcv |> select(site, ends_with("m2_sd"))
    , by = "site") |>
  pivot_longer(ends_with("_sd")) |> 
split(~strm) |> 
  map(
    ~.x |> ggplot() +
  geom_sf(aes(size = value)) +
  scale_size_area() +
  facet_wrap(~name, nrow = 3, drop = T) +
    labs(subtitle = .x$strm[1]) +
    theme(axis.text = element_blank())
    ) |> 
  wrap_plots(ncol = 10)

```


quick look back at ssn, joining in new response measures to 'obs' rather than rebuilding from scratch
to fit ssn_glm.nb on SML_mu would need mean(lgth_wdth offset)? 
or could ssn_glm.nb on SML direct, allowing/including years as independent rather than repeated/longitudinal...could also include 'year' covar but then factor vs ordinal etc.
ssn_glm.gamma runs but then back to interpreting gamma?
ssn_lm of sd_log separately by stream
```{r ssn_redux, include=FALSE, eval=FALSE}
wood_sy_sml_nwm_musdcv |> 
  #ggplot(aes(sample = n_S_1000m2_sd_log, color = strm)) +
  #ggplot(aes(sample = n_S_1000m2_mu, color = strm)) +
  ggplot(aes(sample = log(n_S_1000m2_mu), color = strm)) +
  geom_qq_line() + geom_qq() + facet_wrap(~strm, scales = "free")

s1 <- map(
  ssn[7],
  \(s){
    s$obs <- left_join(s$obs, wood_sy_sml_nwm_musdcv |> select(site, contains('1000m2')), by = "site")
    
    # SSN2::ssn_glm(
    #   formula = n_S_1000m2_mu ~ log10(dasqkm_tot) + log10(elev_min) + slope, #as.formula(paste(lhs, "~", rhs)),
    #   ssn.object = s,
    #   family = "Gamma", tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", additive = "afvArea"
    # )
    
    SSN2::ssn_lm(
      #formula = n_S_1000m2_mu ~ log10(dasqkm_tot) + log10(elev_min) + slope, #as.formula(paste(lhs, "~", rhs)),
      formula = log(n_S_1000m2_mu) ~ log10(dasqkm_tot) + log10(elev_min) + slope, #as.formula(paste(lhs, "~", rhs)),
      #formula = n_M_1000m2_mu ~ log10(dasqkm_tot) + log10(elev_min) + slope, #as.formula(paste(lhs, "~", rhs)),
      #formula = n_L_1000m2_mu ~ log10(dasqkm_tot) + log10(elev_min) + slope, #as.formula(paste(lhs, "~", rhs)),
      #formula = n_S_1000m2_sd_log ~ log10(dasqkm_tot) + log10(elev_min) + slope, #as.formula(paste(lhs, "~", rhs)),
      #formula = n_M_1000m2_sd_log ~ log10(dasqkm_tot) + log10(elev_min) + slope, #as.formula(paste(lhs, "~", rhs)),
      #formula = n_L_1000m2_sd_log ~ log10(dasqkm_tot) + log10(elev_min) + slope, #as.formula(paste(lhs, "~", rhs)),
      ssn.object = s,
      tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", additive = "afvArea"
    )
  }
)
summary(s1$`171100180107_Stavis_55000800121057`)
anova(s1$`171100180107_Stavis_55000800121057`)


sd_log_S <- map(
  ssn,
  \(s){
    s$obs <- left_join(s$obs, wood_sy_sml_nwm_musdcv |> select(site, contains('1000m2')), by = "site")
    SSN2::ssn_lm(
      formula = n_S_1000m2_sd_log ~ log10(dasqkm_tot) + log10(elev_min) + slope, 
      ssn.object = s,
      tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", additive = "afvArea"
    ) 
  }
)
sd_log_L <- map(
  ssn,
  \(s){
    s$obs <- left_join(s$obs, wood_sy_sml_nwm_musdcv |> select(site, contains('1000m2')), by = "site") |> 
      mutate(n_L_1000m2_sd_log = if_else(is.infinite(n_L_1000m2_sd_log), NA, n_L_1000m2_sd_log))
    SSN2::ssn_lm(
      formula = n_L_1000m2_sd_log ~ log10(dasqkm_tot) + log10(elev_min) + slope,
      ssn.object = s,
      tailup_type = "exponential", taildown_type = "none", euclid_type = "gaussian", additive = "afvArea"
    ) 
  }
)


bind_rows(
  map_df(sd_log_S, ~broom::tidy(.x) |> mutate(pseudor2 = .x$pseudoR2, strm = .x$ssn.object$obs$strm[1], wood_class = "S")) 
  ,
  map_df(sd_log_L, ~broom::tidy(.x) |> mutate(pseudor2 = .x$pseudoR2, strm = .x$ssn.object$obs$strm[1], wood_class = "L"))
) |> 
  #select(strm, wood_class, term, p.value) |> pivot_wider(names_from = term, values_from = p.value)
  mutate(p.value = cut(p.value, breaks = c(0,0.01,0.05,0.1,1))) |> 
  ggplot(aes(term, 
             fct_reorder(strm, pseudor2, max),
             color = strm)) +
  geom_point(aes(size = p.value, alpha = p.value)) +
  scale_color_manual(values = pal_strm, aesthetics = c("color","fill")) +
  scale_size_manual(values = c(3,1,0.5,0.1)) +
  scale_alpha_manual(values = c(1,0.9,0.5,0.1)) +
  geom_text(aes(x = '_r2', y = strm, label = round(pseudor2,2)), show.legend = F) +
  guides(color = guide_none()) +
  facet_wrap(~wood_class, ncol = 1) +
  labs(x = NULL, y = NULL,
       title = "Prelim per-stream SSN LMs of log(sd) yearly areal wood density",
    #subtitle = deparse(sd_log_S[[1]]$formula)
    subtitle = str_squish(paste(deparse(sd_log_S[[1]]$call), collapse = "")) |> str_replace("ssn.object = s,","\n")
    )

ggsave("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/fig/f_ssnredux_sd_log.png", width = 9, height = 8, dpi = 150, bg = "white")


sd_log_L$`171100210304_Deep_55000800078356`$ssn.object$obs$n_L_1000m2_sd_log
sd_log_L$`171100210304_Deep_55000800078356`$fitted$response
#sd_log_L$`171100210304_Deep_55000800078356`$ssn.object$obs$n_L_1000m2_sd_log - sd_log_L$`171100210304_Deep_55000800078356`$fitted$response
sd_log_L$`171100210304_Deep_55000800078356`$residuals$response

sd_log_L$`171100210304_Deep_55000800078356`$ssn.object$obs$n_L_1000m2_sd_log |> exp()
exp(sd_log_L$`171100210304_Deep_55000800078356`$fitted$response + 
      sd_log_L$`171100210304_Deep_55000800078356`$residuals$response)

pluck(sd_log_L,  names(ssn)[10], "ssn.object", "obs") |> pull(n_L_1000m2_sd) |> summary()   
pluck(sd_log_L,  names(ssn)[10], "ssn.object", "obs") |> pull(n_L_1000m2_sd_log) |> exp() |> summary()   
pluck(sd_log_L,  names(ssn)[10], "ssn.object", "obs") |> pull(n_L_1000m2_sd_log) |> summary()   
pluck(sd_log_L,  names(ssn)[10], "fitted", "response") |> summary() #fitted is in log()
pluck(sd_log_L,  names(ssn)[10], "fitted", "response") |> exp() |> summary() #so exp() to return to orig 1000m2 scale
pluck(sd_log_L,  names(ssn)[10]) |> predict() |> summary() #predict is also in log, but has values outside obs
pluck(sd_log_L,  names(ssn)[10]) |> predict() |> exp() |> summary() #and exp(preds) at tails considerably greater...

pluck(sd_log_S,  names(ssn)[10], "ssn.object", "obs") |> pull(n_S_1000m2_sd) |> summary()  
pluck(sd_log_S,  names(ssn)[10], "fitted", "response") |> exp() |> summary()
pluck(sd_log_S,  names(ssn)[10]) |> predict() |> exp() |> summary()

#exp(predict) yields some wild values...
map(
  names(ssn)[10],
  \(n){
    left_join(
      ssn[[n]]$edges
      ,
      as_tibble(bind_rows(
        pluck(sd_log_S, n, "ssn.object", "preds", 1) |> 
          mutate(
            wood_class = "S", 
            sd_log_pred = predict(sd_log_S[[ n ]], "preds")
          )
        ,
        pluck(sd_log_L, n, "ssn.object", "preds", 1) |> 
          mutate(
            wood_class = "L", 
            sd_log_pred = predict(sd_log_L[[ n ]], "preds")
          )
      )) |>
        select(NHDPlusID, wood_class, sd_log_pred)
      , by = "NHDPlusID"
    ) |> 
      drop_na(sd_log_pred) |> 
      ggplot() +
      geom_sf(data = ssn[[n]]$edges, linewidth = 0.2, color = "grey30") +
      geom_sf(aes(color = sd_log_pred, linewidth = log10(dasqkm_tot))) +
      geom_sf(
        data = pluck(sd_log_S, n, "ssn.object", "obs") |> 
          select(site, n_S_1000m2_sd_log, n_L_1000m2_sd_log) |> 
          pivot_longer(ends_with("sd_log"), values_to = "sd_log_obs") |> 
          mutate(wood_class = str_sub(name,3,3))
        ,
        aes(size = sd_log_obs, color = sd_log_obs)
      ) +
      scale_linewidth(range = c(0.3, 1.5)) +
      wacolors::scale_color_wa_c("footbridge", reverse = T) +
      #guides(linewidth = guide_none()) +
      facet_wrap(~wood_class, ncol = 1)
  }
)

ggsave("~/T/DFW-Team WDFW Watershed Synthesis - IMW analyses/fig/f_ssnredux_sd_log_map_Deep.png", width = 9, height = 11, dpi = 150, bg = "white")


```

## testing tinyVAST 

```{r test_tidyvast}
#stepping through https://vast-lib.github.io/tinyVAST/articles/web_only/stream_networks.html
#to confirm runable and inspect objects

library(sfnetworks)
library(tinyVAST)
set.seed(101)
options("tinyVAST.verbose" = T)


#sf linstring, 'from' and 'to' attributes
stream <- st_read( file.path(system.file("stream_network",package="tinyVAST"), "East_Fork_Lewis_basin.shp"), quiet=TRUE )
#coerce to rooted tree, overwrites from/to of st_read
(stream = as_sfnetwork(stream)) #86 nodes, 85 edges
ggplot() +
  geom_sf(data = as_tibble(stream)) +
  geom_sf(data = mutate(stream, root = tidygraph::node_is_root()) |> filter(root) |> as_tibble(), color = "blue")
#creates 4 element list
graph = tinyVAST::sfnetwork_mesh( stream )
glimpse(graph)
#adds 'table' data.frame of edge to/from/dist cols and 'Dist_ss' sparse matrix dgCMatrix class
graph$table$dist = graph$table$dist / 1000  # Convert distance scale
graph$Dist_ss
#checking topology...
setdiff(graph$table$to, graph$table$from) #various
setdiff(graph$table$from, graph$table$to) #single, 85, implies directed away-from-root
graph$stream |> mutate(root = tidygraph::node_is_root()) |> as_tibble() |> print(n=Inf) #node 85
graph$stream |> tidygraph::activate("edges") |> filter(to == 85)
graph$stream |> tidygraph::activate("edges") |> filter(from == 85) #flowing 'upward'
#but this was already defined in as_sfnetwork
stream |> mutate(root = tidygraph::node_is_root()) |> as_tibble() |> print(n=Inf)

alpha = 2
kappa = 0.05
# mean(graph$table$dist) * kappa = 0.63 -> exp(-0.63) = 0.5 average correlation
# this is n-nodes vector
omega_s = tinyVAST::simulate_sfnetwork( n=1, sfnetwork_mesh=graph, theta=kappa)[,1]
# sample locations along network
#this is 106 random locations
extrap = activate(stream,"edges") |> st_line_sample(density=1/10000) |> st_union() |> st_cast("POINT")

# Project to sampled locations
# this is n-locations x n-nodes matrix
A_is = sfnetwork_evaluator(
  stream = graph$stream,
  loc = st_coordinates(extrap) 
  )
dim(A_is)
omega_i = (A_is %*% omega_s)[,1] #maybe the "_i" is interpolated? where _s is simulated?
# Simulate sampling
#Count = rpois( n=graph$n, lambda=exp(alpha + omega) )
Count_i = rnorm( n=length(omega_i), mean=alpha + omega_i, sd=0.5 )
# Format into long-form data frame expected by tinyVAST
Data = data.frame( Count = Count_i, #includes negative values
                   st_coordinates(extrap), #coerced to "X" and "Y"
                   var = "species",  # Univariate model so only one value
                   time = "2020",    # no time-dynamics, so only one value
                   dist = "obs" )    # only one type of sampling in data
Data 
#runs to make 12 element list
out = tinyVAST(
  data = Data,
  formula = Count ~ 1,
  spatial_domain = graph,
  space_column = c("X","Y"),
  variable_column = "var",
  time_column = "time",
  distribution_column = "dist",
  space_term = "" 
  )



#both 'rooted tree', but at least this example is 'flowing up' directed "from" root
#while SSNs are 'flowing down' directed "to" root
sf_edges |> filter(str_detect(strm, "Stavis")) |> 
  #as_tibble() |> count(NHDPlusID) |> arrange(desc(n))
  distinct(NHDPlusID, .keep_all = T) |> 
  #mapview::mapview()
  as_sfnetwork() |> #rooted tree
# #equivalently
# ssn$`171100180107_Stavis_55000800121057`$edges |> as_sfnetwork()
  mutate(root = tidygraph::node_is_root()) |> #print(n=Inf) #node 5
  activate("edges") |> 
  #filter(from == 5) #no edges
  filter(to == 5) #the correct to-root-node edge 55000800121057

#need `st_reverse` to prevent error "Stream network has multiple parents for a node, i.e., isn't ordered upstream as assumed"
(s <- ssn$`171100180107_Stavis_55000800121057`$edges |> 
    select(-netID, -netgeom) |>
    st_reverse() |> 
    as_sfnetwork())
(g = tinyVAST::sfnetwork_mesh(s))
g$table$dist = g$table$dist / 1000  # Convert distance scale

#need to construct georef'd obs
#have original site lon-lat in site_meta (as well as year-specific in sf_site_year from transect)
#but want to take advantage of SSNbler snapping to streamlines
#could rewrite wood_sy_sml_nwm_vast construction, retaining NHDPlusID from final join of NHDplusHR edge attributes
#but instead doing expanding join by site of per-year (long) wood counts by class
#does this need dummy "dist[ribution]" column mutated on? 
sites_dropped <- c("STA020", "DEW243", "DEW067", "AND002", "GER004", "SEA064")

(d <- ssn$`171100180107_Stavis_55000800121057`$obs |> 
  select(cmplx_strm:site, NHDPlusID:slope) |> 
  arrange(site) |> 
  filter(!(site %in% sites_dropped)) |> 
  as_tibble() |> 
  mutate(
    X = st_coordinates(geom)[,1],
    Y = st_coordinates(geom)[,2]
  ) |> 
  left_join(wood_sy_sml, by = c("strm","site")) |> 
  left_join(site_comid, by = c("strm","site")) |> 
  left_join(
    nwm |> 
      summarise(
        across(cfs, list(
          #q90 = ~quantile(.,p=c(0.9)),
          #q95 = ~quantile(.,p=c(0.95)) ,
          q99 = ~quantile(.,p=c(0.99)) #,
          #max = ~max(.)
        )),
        .by = c(comid, wy)
      )
    ,
    by = c("comid", "year" = "wy")
  ) |> 
    mutate(dist_col = "obs")
  )

#start with single wood size class
d_S <- filter(d, wood_class == "S") |> droplevels()

tv0 = tinyVAST(
  data = as.data.frame(d_S),
  formula = n ~ 1 + offset(log(lgth_wdth)), # correct for varying survey area
  family = nbinom1(), #no idea whether this is preferable to nbinom2()
  spatial_domain = g,
  space_column = c("X","Y"),
  variable_column = "wood_class",
  time_column = "year",
  distribution_column = "dist_col", #just a repeated character string
  space_term = "" #will want time_term and spacetime_term
  )

tv1 = tinyVAST(
  data = as.data.frame(d_S),
  formula = n ~ 1 + log(dasqkm_tot) + offset(log(lgth_wdth)), # correct for varying survey area
  family = nbinom1(), #no idea whether this is preferable to nbinom2()
  spatial_domain = g,
  space_column = c("X","Y"),
  variable_column = "wood_class",
  time_column = "year",
  distribution_column = "dist_col", #just a repeated character string
  space_term = "" #will want time_term and spacetime_term
  )

tv2 = tinyVAST(
  data = as.data.frame(d_S),
  formula = n ~ 1 + log(dasqkm_tot) + s(year) + offset(log(lgth_wdth)), # correct for varying survey area
  family = nbinom1(), #no idea whether this is preferable to nbinom2()
  spatial_domain = g,
  space_column = c("X","Y"),
  variable_column = "wood_class",
  time_column = "year",
  distribution_column = "dist_col", #just a repeated character string
  space_term = "" #will want time_term and spacetime_term
  )

#adding s(log(cfs_q99)) aborts session
# ---> no time varying covariates?
#adding s(site, bs="re") fails with:  Error in names(dat) <- object$term : 'names' attribute [1] must be the same length as the vector [0] 
# ---> do per-site random effects make sense given spatialautocorr and per-site spatially varied covars?
tv3 = tinyVAST(
  data = as.data.frame(d_S),
  formula = n ~ 1 + log(dasqkm_tot) + s(year) + 
    #BOMBS: s(log(cfs_q99)) + 
    #s(site, bs="re") +
    slope +
    offset(log(lgth_wdth)), # correct for varying survey area
  family = nbinom1(), #no idea whether this is preferable to nbinom2()
  spatial_domain = g,
  space_column = c("X","Y"),
  variable_column = "wood_class",
  time_column = "year",
  distribution_column = "dist_col", #just a repeated character string
  space_term = "" #will want time_term and spacetime_term
  )

tv0
tv1
tv2
tv3
d_S$tv0 <- predict(tv0)
d_S$tv1 <- predict(tv1)
d_S$tv2 <- predict(tv2)
d_S$tv3 <- predict(tv3) #this is actually numerically different but only at thousandths

d_S |> ggplot(aes(year)) + 
  geom_line(aes(y=tv0), color = "grey60") + 
  geom_line(aes(y=tv1), color = "tan") + 
  geom_line(aes(y=tv2), color = "lightblue", linewidth = 1.5) + 
  geom_line(aes(y=tv3), color = "purple", linewidth = 0.5) + 
  geom_point(aes(y=n), size = 0.7) + facet_wrap(~site)


activate(g$stream, "edges") |> 
  left_join(g$table, by = c("from","to")) |> 
  as_tibble() |> 
  ggplot() + geom_sf(aes(color = dist, linewidth = dist)) + scale_linewidth(range = c(0.5,2))

map_df(ls(pattern = "tv"), \(x) tibble(f = x, aic = cAIC(get(x)))) |> 
  bind_cols(
    map_df(ls(pattern = "tv"), ~summary(get(.x)))
  )

map(ls(pattern = "tv"), ~summary(get(.x), "fixed"))
map(ls(pattern = "tv"), ~vcov(get(.x), "fixed"))

```

build topology objects via `tinyVAST::sfnetwork_mesh()` for `spatial_domain =` argument of `tinyVAST()`
this creates 4 element lists from `sfnetwork` rooted trees with edges directed out/upstream/away 'from' root node
adding `table` data.frame of edge to/from/dist cols and `Dist_ss` sparse matrix of class `dgCMatrix`

```{r vast_strm_g}
vast_strm_g <- map(
  ssn,
  \(x){
    g <- x$edges |>
      select(-netID, -netgeom) |>
      mutate(
        cmplx_strm = x$obs$cmplx_strm[1],
        strm = x$obs$strm[1]
      ) |> 
      st_reverse() |> 
      sfnetworks::as_sfnetwork() |> 
      tinyVAST::sfnetwork_mesh()
    g$table$dist <- g$table$dist / 1000
    return(g)
  }
)

vast_strm_g <- set_names(vast_strm_g, map_chr(vast_strm_g, ~as_tibble(.x$stream, "edges")$cmplx_strm[1]))

```

reconstruct georeferenced site observations
could go even further back into emap/hab object creation, where year-specific lon-lat of center transect
but want to take advantage of SSNbler snapping to streamlines
so expanding join by site of per-year wood counts by wood size class
for now constructing as single tibble across streams and wood classes to allow various `split()` lists
```{r vast_strm_d}
sites_dropped <- c("STA020", "DEW243", "DEW067", "AND002", "GER004", "SEA064")

vast_strm_d <- map_df(
  ssn, ~.x$obs |> select(cmplx_strm:site, NHDPlusID:slope)
  ) |> 
    filter(!(site %in% sites_dropped)) |> 
    as_tibble() |> 
  mutate(
    X = st_coordinates(geom)[,1],
    Y = st_coordinates(geom)[,2]
  ) |> 
  left_join(wood_sy_sml, by = c("strm","site")) |> 
  left_join(site_comid, by = c("strm","site")) |> 
  left_join(
    nwm |> 
      summarise(
        across(cfs, list(
          q99 = ~quantile(.,p=c(0.99))
        )),
        .by = c(comid, wy)
      )
    ,
    by = c("comid", "year" = "wy")
  ) |> 
    drop_na(lgth_wdth) |> #missing offset causes abort session bombs
    mutate(
      dist_col = "obs"
      ,
      site = factor(site) #must be factor for: s(site, bs = "re")
      )

summary(vast_strm_d)

```


 - is `nbinom2()` or even a poisson preferable?
 - is (1|site) sensible given the spatial field? 

$$ \log(\text{E}[n]) = \alpha + f(\text{year}) + \beta \cdot \log(\text{dasqkm_tot}) + \text{offset} $$
$$ \text{E}[n] \propto (\text{dasqkm_tot})^{\beta} $$
$$ \text{E}[n] \propto (\text{dasqkm_tot})^{-0.493} $$

```{r}
library(tinyVAST)
set.seed(101)
options("tinyVAST.verbose" = T)


fmla <- formula(n ~ 1 + offset(log(lgth_wdth)))

f1 = tinyVAST::tinyVAST(
  data =  vast_strm_d |> 
    filter(str_detect(strm, "bernath"), wood_class == "S") |> droplevels() |> 
    #summary()
    #drop_na(lgth_wdth) |> 
    drop_na(cfs_q99) |> 
    as.data.frame()
  ,
  formula = fmla, 
  family = tinyVAST::nbinom1(), 
  spatial_domain = vast_strm_g$`LC_Abernathy Creek`,
  space_column = c("X","Y"),
  variable_column = "wood_class",
  time_column = "year",
  distribution_column = "dist_col", #just a repeated character string
  space_term = "" #will want time_term and spacetime_term
  )

f2 <- update(f1, n ~ 1 + s(site, bs = "re") + offset(log(lgth_wdth)))
f3 <- update(f1, n ~ 1 + s(year) + offset(log(lgth_wdth)))
f4 <- update(f1, n ~ 1 + s(log(cfs_q99)) + offset(log(lgth_wdth)))
f5 <- update(f1, n ~ 1 + s(year) + s(log(cfs_q99)) + offset(log(lgth_wdth)))
f6 <- update(f1, n ~ 1 + s(year) + log(dasqkm_tot) + offset(log(lgth_wdth)))
f7 <- update(f1, n ~ 1 + log(dasqkm_tot) + offset(log(lgth_wdth)))

##no dice
#visreg::visreg(f1, "year")
#performance::check_model(f1)

f1$deviance_explained
f2$deviance_explained
f1$sdrep
f2$sdrep #"Hessian of fixed effects was not positive definite."

#this all seems to say that cfs_q99 worse than 'pure year' for S[mall] in Abernathy...
f3$deviance_explained
f4$deviance_explained #worse
f5$deviance_explained #only slightly better than year only
f6$deviance_explained #very slightly worse than s(year) only
AIC(f3) #3899
AIC(f4) #4150, worse
AIC(f5) #3903 basically same as year only
AIC(f6) #3867 very slightly better than year only
AIC(f7) #4119

# alpha_j: site-level intercepts or site effects (the j index is over sites); Reflects the baseline expected log-count (or log-density) at each site, before accounting for spatiotemporal variation.
# theta_z: spatiotemporal random effects (indexed over z, latent factors or spatial knots); deviations from the global mean at each latent spatial location or knot; negative estimate means on average the spatial random effect pulls prediction down
# log_sigma: log of the marginal standard deviation of the spatial random field (how variable the field is across space/time); higher sigma → greater spatial variability in predicted values.
# log_kappa: log of the spatial decay parameter. In SPDE models (as used by VAST), kappa governs how rapidly spatial correlation decays with distance. Lower kappa → longer spatial correlation range; higher kappa → more local variation.

f3$sdrep
f4$sdrep #considerably smaller loglambda, higher logsigma
f5$sdrep
f6$sdrep
f7$sdrep


#start with single wood size class across streams
vast_fit <- tibble(
  cmplx_strm = names(vast_strm_g),
  g = vast_strm_g
  ) |> 
  mutate(
    d_S = map(
      cmplx_strm,
      ~as.data.frame(vast_strm_d) |> 
        filter(cmplx_strm == .x, wood_class == "S") |> 
        droplevels()
    )
    ,
    #intercept only 
    d_S_f0 = map2(
      d_S, g,
      ~tinyVAST(
        data = .x,
        formula = n ~ 1 + offset(log(lgth_wdth)), # correct for varying survey area
        family = nbinom1(), #no idea whether this is preferable to nbinom2()
        spatial_domain = .y,
        space_column = c("X","Y"),
        variable_column = "wood_class",
        time_column = "year",
        distribution_column = "dist_col", #just a repeated character string
        space_term = "" #will want time_term and spacetime_term
      )      
    )
    ,
    ##unclear why update() works on standalone but not list element of same class
    # class(vast_fit$d_S_f0[[1]])
    # update(vast_fit$d_S_f0[[1]], n ~ 1 + log(dasqkm_tot) + offset(log(lgth_wdth)))
    ##but just refitting directly with explicit new formula for now
    ##can write a wrapper later to tighten up
    #add drainage area
    d_S_f1 = map2(
      d_S, g,
      ~tinyVAST(
        data = .x,
        formula = n ~ 1 + log(dasqkm_tot) + offset(log(lgth_wdth)), # correct for varying survey area
        family = nbinom1(), #no idea whether this is preferable to nbinom2()
        spatial_domain = .y,
        space_column = c("X","Y"),
        variable_column = "wood_class",
        time_column = "year",
        distribution_column = "dist_col", #just a repeated character string
        space_term = "" #will want time_term and spacetime_term
      )      
    )
    ,
    #add smooth year
    d_S_f2 = map2(
      d_S, g,
      ~tinyVAST(
        data = .x,
        formula = n ~ 1 + s(year) + log(dasqkm_tot) + offset(log(lgth_wdth)), # correct for varying survey area
        family = nbinom1(), #no idea whether this is preferable to nbinom2()
        spatial_domain = .y,
        space_column = c("X","Y"),
        variable_column = "wood_class",
        time_column = "year",
        distribution_column = "dist_col", #just a repeated character string
        space_term = "" #will want time_term and spacetime_term
      )      
    )
  )


vast_fit |> 
  mutate(
    across(
      contains("_f"), 
      list(
        #pdH = ~map_dbl(., ~.x$sdrep$pdHess),
        devxpl = ~map_dbl(., ~.x$deviance_explained),
        aic = ~map_dbl(., ~AIC(.x))
        )
      )
    # pdH = map_dbl(d_S_f0, ~.x$sdrep$pdHess),
    # devxpl = map_dbl(d_S_f0, ~.x$deviance_explained),
    # op = map(
    #   d_S_f0, \(f){
    #     gg <- f$data |> 
    #       mutate(
    #         p = f$rep$mu_i #p = predict(f)
    #         ) |> 
    #       ggplot(aes(n, p, group = site)) + geom_point(alpha = 0.7, size = 0.5) + geom_abline(intercept = 0, linetype = 3)
    #   }
    # )
  )




vast_fit$d_S_f0[[1]]$sdrep
summary(vast_fit$d_S_f0[[1]]$sdrep, "fixed")
summary(vast_fit$d_S_f0[[1]]$sdrep, "fixed", p.value = T)

vast_fit$d_S_f0[[1]]

#nice overview: https://library.virginia.edu/data/articles/understanding-deviance-residuals
quantile(vast_fit$d_S_f0[[1]]$rep$devresid_i) #hoping for roughly even +/- centered on 0, abs(min/max) < 3 


tibble(
  obs = vast_fit$d_S_f0[[1]]$data$n,
  pred1 = vast_fit$d_S_f0[[1]]$rep$mu_i,
  #pred2 = predict(vast_fit$d_S_f0[[1]]),
  rawresid = obs - pred1, #not a thing: residuals(vast_fit$d_S_f0[[1]], type = "response")
  devresid = vast_fit$d_S_f0[[1]]$rep$devresid_i
) |> summary()




#phHess is whether the Hessian is positive-definite, if False, go back and refit
#sdrep will show you your effects and the standard deviation on the estimate. 
#if the CV of the effect is super high, or the implied CI covers zero, consider dropping that effect
# then I go to DHARMa
# then I go back to basics, and just do plots of observed/predicted values

 
```

